{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"STAR_BikeNYC.ipynb","provenance":[],"authorship_tag":"ABX9TyNU71VuqimprgOwQjd/n5fN"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"3vPGzXMBvHmS","executionInfo":{"status":"ok","timestamp":1602339214185,"user_tz":-120,"elapsed":1961,"user":{"displayName":"Roberto Tagliabue","photoUrl":"","userId":"09447467556359440393"}},"outputId":"760ab0f4-92c7-49d7-d252-2a28e8673b64","colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["from google.colab import drive\n","drive.mount('/content/drive/', force_remount=True)"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive/\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"0aMAQeMCvMD-","executionInfo":{"status":"ok","timestamp":1602339216356,"user_tz":-120,"elapsed":970,"user":{"displayName":"Roberto Tagliabue","photoUrl":"","userId":"09447467556359440393"}}},"source":["import os\n","os.chdir('./drive/My Drive/TESI/STAR')"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"WiV2CoZjvRy3","executionInfo":{"status":"ok","timestamp":1602339226071,"user_tz":-120,"elapsed":2337,"user":{"displayName":"Roberto Tagliabue","photoUrl":"","userId":"09447467556359440393"}}},"source":["from __future__ import print_function\n","import os\n","import _pickle as pickle\n","import numpy as np\n","import math\n","import h5py\n","\n","from keras.optimizers import Adam\n","from keras.callbacks import EarlyStopping, ModelCheckpoint,TensorBoard, LearningRateScheduler\n","from star.model import *\n","from star.config import Config\n","import star.metrics as metrics\n","from star import BikeNYC\n","\n","np.random.seed(1337)  # for reproducibility"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"VwIxjmZ_vpml","executionInfo":{"status":"ok","timestamp":1602339229861,"user_tz":-120,"elapsed":946,"user":{"displayName":"Roberto Tagliabue","photoUrl":"","userId":"09447467556359440393"}},"outputId":"31baa62c-87fd-4728-bc8d-8cd5fb70f5e8","colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["# parameters\n","DATAPATH = '../data' \n","nb_epoch = 200  # number of epoch at training stage\n","nb_epoch_cont = 150  # number of epoch at training (cont) stage\n","batch_size = 16  # batch size\n","T = 24  # number of time intervals in one day\n","CACHEDATA = True  # cache data or NOT\n","\n","lr = 0.00015  # learning rate\n","len_closeness = 3  # length of closeness dependent sequence\n","len_period = 1  # length of peroid dependent sequence\n","len_trend = 1  # length of trend dependent sequence\n","nb_residual_unit = 2   # number of residual units\n","\n","nb_flow = 2  # there are two types of flows: new-flow and end-flow\n","# divide data into two subsets: Train & Test, of which the test set is the\n","# last 10 days\n","days_test = 10\n","len_test = T*days_test\n","len_val = 2*len_test\n","\n","map_height, map_width = 16, 8  # grid size\n","# For NYC Bike data, there are 81 available grid-based areas, each of\n","# which includes at least ONE bike station. Therefore, we modify the final\n","# RMSE by multiplying the following factor (i.e., factor).\n","nb_area = 81\n","m_factor = math.sqrt(1. * map_height * map_width / nb_area)\n","print('factor: ', m_factor)\n","\n","path_cache = os.path.join(DATAPATH, 'CACHE', 'STAR')  # cache path\n","path_result = 'RET'\n","path_model = 'MODEL'\n","if os.path.isdir(path_result) is False:\n","    os.mkdir(path_result)\n","if os.path.isdir(path_model) is False:\n","    os.mkdir(path_model)\n","if CACHEDATA and os.path.isdir(path_cache) is False:\n","    os.mkdir(path_cache)\n"],"execution_count":4,"outputs":[{"output_type":"stream","text":["factor:  1.2570787221094177\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"LnFWAP7svvGs","executionInfo":{"status":"ok","timestamp":1602339233055,"user_tz":-120,"elapsed":860,"user":{"displayName":"Roberto Tagliabue","photoUrl":"","userId":"09447467556359440393"}}},"source":["def build_model(external_dim, save_model_pic=False):\n","    c_conf = (len_closeness, nb_flow, map_height,\n","              map_width) if len_closeness > 0 else None\n","    p_conf = (len_period, nb_flow, map_height,\n","              map_width) if len_period > 0 else None\n","    t_conf = (len_trend, nb_flow, map_height,\n","              map_width) if len_trend > 0 else None\n","\n","    model = STAR(c_conf=c_conf, p_conf=p_conf, t_conf=t_conf,\n","                     external_dim=external_dim, nb_residual_unit=nb_residual_unit)\n","    adam = Adam(lr=lr)\n","    model.compile(loss='mse', optimizer=adam, metrics=[metrics.rmse])\n","    # model.summary()\n","    if (save_model_pic):\n","        from keras.utils.vis_utils import plot_model\n","        plot_model(model, to_file='BikeNYC_model.png', show_shapes=True)\n","\n","    return model"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"QKPT4RftvCww","executionInfo":{"status":"ok","timestamp":1602339237148,"user_tz":-120,"elapsed":953,"user":{"displayName":"Roberto Tagliabue","photoUrl":"","userId":"09447467556359440393"}}},"source":["def read_cache(fname):\n","    mmn = pickle.load(open('preprocessing_nyc.pkl', 'rb'))\n","\n","    f = h5py.File(fname, 'r')\n","    num = int(f['num'].value)\n","    X_train_all, Y_train_all, X_train, Y_train, X_val, Y_val, X_test, Y_test = [], [], [], [], [], [], [], []\n","    for i in range(num):\n","        X_train_all.append(f['X_train_all_%i' % i].value)\n","        X_train.append(f['X_train_%i' % i].value)\n","        X_val.append(f['X_val_%i' % i].value)\n","        X_test.append(f['X_test_%i' % i].value)\n","    Y_train_all = f['Y_train_all'].value\n","    Y_train = f['Y_train'].value\n","    Y_val = f['Y_val'].value\n","    Y_test = f['Y_test'].value\n","    external_dim = f['external_dim'].value\n","    timestamp_train_all = f['T_train_all'].value\n","    timestamp_train = f['T_train'].value\n","    timestamp_val = f['T_val'].value\n","    timestamp_test = f['T_test'].value\n","    f.close()\n","\n","    return X_train_all, Y_train_all, X_train, Y_train, X_val, Y_val, X_test, Y_test, mmn, external_dim, timestamp_train_all, timestamp_train, timestamp_val, timestamp_test\n","\n","def cache(fname, X_train_all, Y_train_all, X_train, Y_train, X_val, Y_val, X_test, Y_test, external_dim, timestamp_train_all, timestamp_train, timestamp_val, timestamp_test):\n","    h5 = h5py.File(fname, 'w')\n","    h5.create_dataset('num', data=len(X_train_all))\n","\n","    for i, data in enumerate(X_train_all):\n","        h5.create_dataset('X_train_all_%i' % i, data=data)\n","    for i, data in enumerate(X_train):\n","        h5.create_dataset('X_train_%i' % i, data=data)\n","    for i, data in enumerate(X_val):\n","        h5.create_dataset('X_val_%i' % i, data=data)\n","    # for i, data in enumerate(Y_train):\n","    for i, data in enumerate(X_test):\n","        h5.create_dataset('X_test_%i' % i, data=data)\n","\n","    h5.create_dataset('Y_train_all', data=Y_train_all)\n","    h5.create_dataset('Y_train', data=Y_train)\n","    h5.create_dataset('Y_val', data=Y_val)\n","    h5.create_dataset('Y_test', data=Y_test)\n","    external_dim = -1 if external_dim is None else int(external_dim)\n","    h5.create_dataset('external_dim', data=external_dim)\n","    h5.create_dataset('T_train_all', data=timestamp_train_all)\n","    h5.create_dataset('T_train', data=timestamp_train)\n","    h5.create_dataset('T_val', data=timestamp_val)\n","    h5.create_dataset('T_test', data=timestamp_test)\n","    h5.close()\n","\n","def lrschedule(epoch):\n","    if epoch <= 25:\n","        return 0.0002\n","    elif epoch <= 50:\n","        return 0.00015\n","    elif epoch <= 75:\n","        return 0.0001\n","    elif epoch <= 100:\n","        return 0.00005\n","    else: return 0.00001\n"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"oJAWxuKS005o","executionInfo":{"status":"ok","timestamp":1602339239999,"user_tz":-120,"elapsed":836,"user":{"displayName":"Roberto Tagliabue","photoUrl":"","userId":"09447467556359440393"}},"outputId":"a9eccac3-8b30-4f94-8398-6195685534b8","colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["tf.keras.backend.set_image_data_format('channels_first')\n","tf.keras.backend.image_data_format()"],"execution_count":7,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'channels_first'"]},"metadata":{"tags":[]},"execution_count":7}]},{"cell_type":"code","metadata":{"id":"TisNOsy6wDE1","executionInfo":{"status":"error","timestamp":1602339245009,"user_tz":-120,"elapsed":2708,"user":{"displayName":"Roberto Tagliabue","photoUrl":"","userId":"09447467556359440393"}},"outputId":"85b5c697-beda-484f-8b69-6ea9003d7557","colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["dic_rmse = {}\n","for i in range(0,10):\n","    print(\"loading data...\")\n","    fname = os.path.join(path_cache, 'BikeNYC_C{}_P{}_T{}.h5'.format(\n","        len_closeness, len_period, len_trend))\n","    if os.path.exists(fname) and CACHEDATA:\n","        X_train_all, Y_train_all, X_train, Y_train, \\\n","        X_val, Y_val, X_test, Y_test, mmn, external_dim, \\\n","        timestamp_train_all, timestamp_train, timestamp_val, timestamp_test = read_cache(\n","            fname)\n","        print(\"load %s successfully\" % fname)\n","    else:\n","        X_train_all, Y_train_all, X_train, Y_train, \\\n","        X_val, Y_val, X_test, Y_test, mmn, external_dim, \\\n","        timestamp_train_all, timestamp_train, timestamp_val, timestamp_test = BikeNYC.load_data(\n","            T=T, nb_flow=nb_flow, len_closeness=len_closeness, len_period=len_period, len_trend=len_trend, len_test=len_test,\n","            len_val=len_val, preprocess_name='preprocessing_nyc.pkl', meta_data=True, datapath=DATAPATH)\n","        if CACHEDATA:\n","            cache(fname, X_train_all, Y_train_all, X_train, Y_train, X_val, Y_val, X_test, Y_test,\n","                  external_dim, timestamp_train_all, timestamp_train, timestamp_val, timestamp_test)\n","\n","    print(\"\\n days (test): \", [v[:8] for v in timestamp_test[0::T]])\n","\n","    print('=' * 10)\n","    print(\"compiling model...\")\n","\n","    lr_callback = LearningRateScheduler(lrschedule)\n","\n","    model = build_model(external_dim, save_model_pic=True)\n","\n","    hyperparams_name = 'BikeNYC.c{}.p{}.t{}.resunit{}.iter{}'.format(\n","        len_closeness, len_period, len_trend, nb_residual_unit, i)\n","    fname_param = os.path.join(path_model, '{}.best.h5'.format(hyperparams_name))\n","    print(hyperparams_name)\n","\n","    early_stopping = EarlyStopping(monitor='val_rmse', patience=4, mode='min')\n","    model_checkpoint = ModelCheckpoint(\n","        fname_param, monitor='val_rmse', verbose=0, save_best_only=True, mode='min')\n","\n","    print('=' * 10)\n","    print(\"training model...\")\n","    history = model.fit(X_train, Y_train,\n","                        epochs=nb_epoch,\n","                        batch_size=batch_size,\n","                        validation_data=(X_val,Y_val),\n","                        callbacks=[early_stopping, model_checkpoint],\n","                        verbose=2)\n","    model.save_weights(os.path.join(\n","        path_model, '{}.h5'.format(hyperparams_name)), overwrite=True)\n","    pickle.dump((history.history), open(os.path.join(\n","        path_result, '{}.history.pkl'.format(hyperparams_name)), 'wb'))\n","\n","    print('=' * 10)\n","    print('evaluating using the model that has the best loss on the valid set')\n","\n","    model.load_weights(fname_param)\n","    score = model.evaluate(X_train, Y_train, batch_size=Y_train.shape[\n","                            0] // 48, verbose=0)\n","    print('Train score: %.6f rmse (norm): %.6f rmse (real): %.6f' %\n","          (score[0], score[1], score[1] * (mmn._max - mmn._min) / 2. * m_factor))\n","\n","    score = model.evaluate(\n","        X_test, Y_test, batch_size=Y_test.shape[0], verbose=0)\n","    print('Test score: %.6f rmse (norm): %.6f rmse (real): %.6f' %\n","          (score[0], score[1], score[1] * (mmn._max - mmn._min) / 2. * m_factor))\n","\n","    print('=' * 10)\n","    print(\"training model (cont)...\")\n","    fname_param = os.path.join(\n","        path_model, '{}.cont.best.h5'.format(hyperparams_name))\n","    model_checkpoint = ModelCheckpoint(\n","        fname_param, monitor='rmse', verbose=0, save_best_only=True, mode='min')\n","    history = model.fit(X_train_all, Y_train_all,\n","                        nb_epoch=nb_epoch_cont,\n","                        verbose=2,\n","                        batch_size=batch_size,\n","                        callbacks=[lr_callback, model_checkpoint],\n","                        validation_data=(X_test, Y_test))\n","    pickle.dump((history.history), open(os.path.join(\n","        path_result, '{}.cont.history.pkl'.format(hyperparams_name)), 'wb'))\n","    model.save_weights(os.path.join(\n","        path_model, '{}_cont.h5'.format(hyperparams_name)), overwrite=True)\n","\n","    print('=' * 10)\n","    print('evaluating using the final model')\n","    score = model.evaluate(X_train_all, Y_train_all, batch_size=Y_train.shape[\n","                            0] // 48, verbose=0)\n","    print('Train score: %.6f rmse (norm): %.6f rmse (real): %.6f' %\n","          (score[0], score[1], score[1] * (mmn._max - mmn._min) / 2. * m_factor))\n","\n","    score = model.evaluate(\n","        X_test, Y_test, batch_size=Y_test.shape[0], verbose=0)\n","    print('Test score: %.6f rmse (norm): %.6f rmse (real): %.6f' %\n","          (score[0], score[1], score[1] * (mmn._max - mmn._min) / 2. * m_factor))\n","    # dic_rmse[hyperparams_name] = score[1] * (mmn._max - mmn._min) / 2. * m_factor\n","# os.system('rm /home/suhan/wanghn/DeepST/data/CACHE/'+'BikeNYC_C{}_P{}_T{}.h5'.format(\n","        # len_closeness, len_period, len_trend))\n","# print(sorted(dic_rmse.items(), key=lambda item:item[1]))"],"execution_count":8,"outputs":[{"output_type":"stream","text":["loading data...\n","load ../data/CACHE/STAR/BikeNYC_C3_P1_T1.h5 successfully\n","\n"," days (test):  [b'20140921', b'20140922', b'20140923', b'20140924', b'20140925', b'20140926', b'20140927', b'20140928', b'20140929', b'20140930']\n","==========\n","compiling model...\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:5: H5pyDeprecationWarning: dataset.value has been deprecated. Use dataset[()] instead.\n","  \"\"\"\n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:8: H5pyDeprecationWarning: dataset.value has been deprecated. Use dataset[()] instead.\n","  \n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:9: H5pyDeprecationWarning: dataset.value has been deprecated. Use dataset[()] instead.\n","  if __name__ == '__main__':\n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:10: H5pyDeprecationWarning: dataset.value has been deprecated. Use dataset[()] instead.\n","  # Remove the CWD from sys.path while we load stuff.\n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:11: H5pyDeprecationWarning: dataset.value has been deprecated. Use dataset[()] instead.\n","  # This is added back by InteractiveShellApp.init_path()\n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:12: H5pyDeprecationWarning: dataset.value has been deprecated. Use dataset[()] instead.\n","  if sys.path[0] == '':\n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:13: H5pyDeprecationWarning: dataset.value has been deprecated. Use dataset[()] instead.\n","  del sys.path[0]\n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:14: H5pyDeprecationWarning: dataset.value has been deprecated. Use dataset[()] instead.\n","  \n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:15: H5pyDeprecationWarning: dataset.value has been deprecated. Use dataset[()] instead.\n","  from ipykernel import kernelapp as app\n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:16: H5pyDeprecationWarning: dataset.value has been deprecated. Use dataset[()] instead.\n","  app.launch_new_instance()\n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:17: H5pyDeprecationWarning: dataset.value has been deprecated. Use dataset[()] instead.\n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:18: H5pyDeprecationWarning: dataset.value has been deprecated. Use dataset[()] instead.\n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:19: H5pyDeprecationWarning: dataset.value has been deprecated. Use dataset[()] instead.\n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:20: H5pyDeprecationWarning: dataset.value has been deprecated. Use dataset[()] instead.\n"],"name":"stderr"},{"output_type":"stream","text":["BikeNYC.c3.p1.t1.resunit2.iter0\n","==========\n","training model...\n","Epoch 1/200\n"],"name":"stdout"},{"output_type":"error","ename":"InvalidArgumentError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)","\u001b[0;32m<ipython-input-8-730a2ba34cc9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     41\u001b[0m                         \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m                         \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mearly_stopping\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_checkpoint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m                         verbose=2)\n\u001b[0m\u001b[1;32m     44\u001b[0m     model.save_weights(os.path.join(\n\u001b[1;32m     45\u001b[0m         path_model, '{}.h5'.format(hyperparams_name)), overwrite=True)\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1099\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    838\u001b[0m         \u001b[0;31m# Lifting succeeded, so variables are initialized and we can run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    839\u001b[0m         \u001b[0;31m# stateless function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 840\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    841\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    842\u001b[0m       \u001b[0mcanon_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcanon_kwds\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2829\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2831\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1846\u001b[0m                            resource_variable_ops.BaseResourceVariable))],\n\u001b[1;32m   1847\u001b[0m         \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1848\u001b[0;31m         cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1850\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1922\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1923\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1924\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1926\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    548\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m           outputs = execute.execute_with_cancellation(\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mInvalidArgumentError\u001b[0m:  Conv2DCustomBackpropInputOp only supports NHWC.\n\t [[node gradient_tape/functional_1/conv2d_5/Conv2D/Conv2DBackpropInput (defined at <ipython-input-8-730a2ba34cc9>:43) ]] [Op:__inference_train_function_1432]\n\nFunction call stack:\ntrain_function\n"]}]}]}