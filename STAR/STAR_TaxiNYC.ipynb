{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"STAR_TaxiNYC.ipynb","provenance":[],"authorship_tag":"ABX9TyOdwzdcem6m9l6go5uPDuAT"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"xSmUmeTrAZrf","executionInfo":{"status":"ok","timestamp":1605194895335,"user_tz":-60,"elapsed":1877,"user":{"displayName":"Roberto Tagliabue","photoUrl":"","userId":"09447467556359440393"}},"outputId":"cc9b5c25-6378-47de-d52a-67e8529a881d","colab":{"base_uri":"https://localhost:8080/"}},"source":["from google.colab import drive\n","drive.mount('/content/drive/', force_remount=True)\n","import os\n","os.chdir('./drive/My Drive/TESI/STAR')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive/\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ObEGPcjrAnuc","executionInfo":{"status":"ok","timestamp":1605194898888,"user_tz":-60,"elapsed":1918,"user":{"displayName":"Roberto Tagliabue","photoUrl":"","userId":"09447467556359440393"}}},"source":["from __future__ import print_function\n","import os\n","import _pickle as pickle\n","import numpy as np\n","import math\n","import h5py\n","\n","from keras.optimizers import Adam, SGD\n","from keras.callbacks import EarlyStopping, ModelCheckpoint,TensorBoard, LearningRateScheduler\n","from star.model import *\n","import star.metrics as metrics\n","from star import TaxiNYC\n","\n","np.random.seed(1337)  # for reproducibility"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"gkjt3NTfAxD5","executionInfo":{"status":"ok","timestamp":1605194904182,"user_tz":-60,"elapsed":597,"user":{"displayName":"Roberto Tagliabue","photoUrl":"","userId":"09447467556359440393"}}},"source":["# parameters\n","DATAPATH = '../data' \n","nb_epoch = 100  # number of epoch at training stage\n","# nb_epoch_cont = 150  # number of epoch at training (cont) stage\n","batch_size = 16  # batch size\n","T = 24  # number of time intervals in one day\n","CACHEDATA = True  # cache data or NOT\n","\n","lr = 0.00015  # learning rate\n","len_closeness = 3  # length of closeness dependent sequence\n","len_period = 1  # length of peroid dependent sequence\n","len_trend = 1  # length of trend dependent sequence\n","nb_residual_unit = 2   # number of residual units\n","\n","nb_flow = 2  # there are two types of flows: new-flow and end-flow\n","# divide data into two subsets: Train & Test, \n","days_test = 7*4\n","len_test = T*days_test\n","len_val = 2*len_test\n","\n","map_height, map_width = 16, 8  # grid size\n","\n","path_cache = os.path.join(DATAPATH, 'CACHE', 'STAR')  # cache path\n","path_result = 'RET'\n","path_model = 'MODEL'\n","if os.path.isdir(path_result) is False:\n","    os.mkdir(path_result)\n","if os.path.isdir(path_model) is False:\n","    os.mkdir(path_model)\n","if CACHEDATA and os.path.isdir(path_cache) is False:\n","    os.mkdir(path_cache)"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"7fRWxQaQA1Z1","executionInfo":{"status":"ok","timestamp":1605194907187,"user_tz":-60,"elapsed":573,"user":{"displayName":"Roberto Tagliabue","photoUrl":"","userId":"09447467556359440393"}}},"source":["def build_model(external_dim, save_model_pic=False):\n","    c_conf = (len_closeness, nb_flow, map_height,\n","              map_width) if len_closeness > 0 else None\n","    p_conf = (len_period, nb_flow, map_height,\n","              map_width) if len_period > 0 else None\n","    t_conf = (len_trend, nb_flow, map_height,\n","              map_width) if len_trend > 0 else None\n","\n","    model = STAR(c_conf=c_conf, p_conf=p_conf, t_conf=t_conf,\n","                     external_dim=external_dim, nb_residual_unit=nb_residual_unit)\n","    opt = Adam(lr=lr)\n","    # opt = SGD(lr=lr)\n","    model.compile(loss='mse', optimizer=opt, metrics=[metrics.rmse])\n","    # model.summary()\n","    if (save_model_pic):\n","        from keras.utils.vis_utils import plot_model\n","        plot_model(model, to_file='TaxiNYC_model.png', show_shapes=True)\n","\n","    return model"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"dDM-aSUfA63N","executionInfo":{"status":"ok","timestamp":1605194909570,"user_tz":-60,"elapsed":550,"user":{"displayName":"Roberto Tagliabue","photoUrl":"","userId":"09447467556359440393"}}},"source":["def read_cache(fname):\n","    mmn = pickle.load(open('preprocessing_taxinyc.pkl', 'rb'))\n","\n","    f = h5py.File(fname, 'r')\n","    num = int(f['num'].value)\n","    X_train_all, Y_train_all, X_train, Y_train, X_val, Y_val, X_test, Y_test = [], [], [], [], [], [], [], []\n","    for i in range(num):\n","        X_train_all.append(f['X_train_all_%i' % i].value)\n","        X_train.append(f['X_train_%i' % i].value)\n","        X_val.append(f['X_val_%i' % i].value)\n","        X_test.append(f['X_test_%i' % i].value)\n","    Y_train_all = f['Y_train_all'].value\n","    Y_train = f['Y_train'].value\n","    Y_val = f['Y_val'].value\n","    Y_test = f['Y_test'].value\n","    external_dim = f['external_dim'].value\n","    timestamp_train_all = f['T_train_all'].value\n","    timestamp_train = f['T_train'].value\n","    timestamp_val = f['T_val'].value\n","    timestamp_test = f['T_test'].value\n","    f.close()\n","\n","    return X_train_all, Y_train_all, X_train, Y_train, X_val, Y_val, X_test, Y_test, mmn, external_dim, timestamp_train_all, timestamp_train, timestamp_val, timestamp_test\n","\n","def cache(fname, X_train_all, Y_train_all, X_train, Y_train, X_val, Y_val, X_test, Y_test, external_dim, timestamp_train_all, timestamp_train, timestamp_val, timestamp_test):\n","    h5 = h5py.File(fname, 'w')\n","    h5.create_dataset('num', data=len(X_train_all))\n","\n","    for i, data in enumerate(X_train_all):\n","        h5.create_dataset('X_train_all_%i' % i, data=data)\n","    for i, data in enumerate(X_train):\n","        h5.create_dataset('X_train_%i' % i, data=data)\n","    for i, data in enumerate(X_val):\n","        h5.create_dataset('X_val_%i' % i, data=data)\n","    # for i, data in enumerate(Y_train):\n","    for i, data in enumerate(X_test):\n","        h5.create_dataset('X_test_%i' % i, data=data)\n","\n","    h5.create_dataset('Y_train_all', data=Y_train_all)\n","    h5.create_dataset('Y_train', data=Y_train)\n","    h5.create_dataset('Y_val', data=Y_val)\n","    h5.create_dataset('Y_test', data=Y_test)\n","    external_dim = -1 if external_dim is None else int(external_dim)\n","    h5.create_dataset('external_dim', data=external_dim)\n","    h5.create_dataset('T_train_all', data=timestamp_train_all)\n","    h5.create_dataset('T_train', data=timestamp_train)\n","    h5.create_dataset('T_val', data=timestamp_val)\n","    h5.create_dataset('T_test', data=timestamp_test)\n","    h5.close()\n"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"4psWJuNJBDKM","executionInfo":{"status":"ok","timestamp":1605194913292,"user_tz":-60,"elapsed":988,"user":{"displayName":"Roberto Tagliabue","photoUrl":"","userId":"09447467556359440393"}},"outputId":"f56dc201-e572-452e-814b-05057c4f7db1","colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["tf.keras.backend.set_image_data_format('channels_first')\n","tf.keras.backend.image_data_format()"],"execution_count":6,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'channels_first'"]},"metadata":{"tags":[]},"execution_count":6}]},{"cell_type":"code","metadata":{"id":"sqorXuuhEudb","executionInfo":{"status":"ok","timestamp":1605194917470,"user_tz":-60,"elapsed":3447,"user":{"displayName":"Roberto Tagliabue","photoUrl":"","userId":"09447467556359440393"}},"outputId":"86ff35b0-2db2-4c68-da4d-4da0b7091c03","colab":{"base_uri":"https://localhost:8080/"}},"source":["print(\"loading data...\")\n","fname = os.path.join(path_cache, 'TaxiNYC_C{}_P{}_T{}.h5'.format(\n","    len_closeness, len_period, len_trend))\n","if os.path.exists(fname) and CACHEDATA:\n","    X_train_all, Y_train_all, X_train, Y_train, \\\n","    X_val, Y_val, X_test, Y_test, mmn, external_dim, \\\n","    timestamp_train_all, timestamp_train, timestamp_val, timestamp_test = read_cache(\n","        fname)\n","    print(\"load %s successfully\" % fname)\n","else:\n","    X_train_all, Y_train_all, X_train, Y_train, \\\n","    X_val, Y_val, X_test, Y_test, mmn, external_dim, \\\n","    timestamp_train_all, timestamp_train, timestamp_val, timestamp_test = TaxiNYC.load_data(\n","        T=T, nb_flow=nb_flow, len_closeness=len_closeness, len_period=len_period, len_trend=len_trend, len_test=len_test,\n","        len_val=len_val, preprocess_name='preprocessing_taxinyc.pkl', meta_data=True, datapath=DATAPATH)\n","    if CACHEDATA:\n","        cache(fname, X_train_all, Y_train_all, X_train, Y_train, X_val, Y_val, X_test, Y_test,\n","              external_dim, timestamp_train_all, timestamp_train, timestamp_val, timestamp_test)\n","\n","print(\"\\n days (test): \", [v[:8] for v in timestamp_test[0::T]])\n","\n","print('=' * 10)"],"execution_count":7,"outputs":[{"output_type":"stream","text":["loading data...\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:5: H5pyDeprecationWarning: dataset.value has been deprecated. Use dataset[()] instead.\n","  \"\"\"\n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:8: H5pyDeprecationWarning: dataset.value has been deprecated. Use dataset[()] instead.\n","  \n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:9: H5pyDeprecationWarning: dataset.value has been deprecated. Use dataset[()] instead.\n","  if __name__ == '__main__':\n"],"name":"stderr"},{"output_type":"stream","text":["load ../data/CACHE/STAR/TaxiNYC_C3_P1_T1.h5 successfully\n","\n"," days (test):  [b'20141204', b'20141205', b'20141206', b'20141207', b'20141208', b'20141209', b'20141210', b'20141211', b'20141212', b'20141213', b'20141214', b'20141215', b'20141216', b'20141217', b'20141218', b'20141219', b'20141220', b'20141221', b'20141222', b'20141223', b'20141224', b'20141225', b'20141226', b'20141227', b'20141228', b'20141229', b'20141230', b'20141231']\n","==========\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:10: H5pyDeprecationWarning: dataset.value has been deprecated. Use dataset[()] instead.\n","  # Remove the CWD from sys.path while we load stuff.\n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:11: H5pyDeprecationWarning: dataset.value has been deprecated. Use dataset[()] instead.\n","  # This is added back by InteractiveShellApp.init_path()\n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:12: H5pyDeprecationWarning: dataset.value has been deprecated. Use dataset[()] instead.\n","  if sys.path[0] == '':\n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:13: H5pyDeprecationWarning: dataset.value has been deprecated. Use dataset[()] instead.\n","  del sys.path[0]\n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:14: H5pyDeprecationWarning: dataset.value has been deprecated. Use dataset[()] instead.\n","  \n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:15: H5pyDeprecationWarning: dataset.value has been deprecated. Use dataset[()] instead.\n","  from ipykernel import kernelapp as app\n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:16: H5pyDeprecationWarning: dataset.value has been deprecated. Use dataset[()] instead.\n","  app.launch_new_instance()\n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:17: H5pyDeprecationWarning: dataset.value has been deprecated. Use dataset[()] instead.\n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:18: H5pyDeprecationWarning: dataset.value has been deprecated. Use dataset[()] instead.\n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:19: H5pyDeprecationWarning: dataset.value has been deprecated. Use dataset[()] instead.\n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:20: H5pyDeprecationWarning: dataset.value has been deprecated. Use dataset[()] instead.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"3UfYB1qlKXwu","executionInfo":{"status":"ok","timestamp":1605194924554,"user_tz":-60,"elapsed":1425,"user":{"displayName":"Roberto Tagliabue","photoUrl":"","userId":"09447467556359440393"}},"outputId":"2bedee97-2fc1-4758-c595-797a6a6545a6","colab":{"base_uri":"https://localhost:8080/"}},"source":["X_val[0].mean()"],"execution_count":8,"outputs":[{"output_type":"execute_result","data":{"text/plain":["-0.9795904128831029"]},"metadata":{"tags":[]},"execution_count":8}]},{"cell_type":"code","metadata":{"id":"IRRjlct0BG9c","executionInfo":{"status":"ok","timestamp":1605195518267,"user_tz":-60,"elapsed":591518,"user":{"displayName":"Roberto Tagliabue","photoUrl":"","userId":"09447467556359440393"}},"outputId":"7f54645a-77d8-4e11-be49-4c78be8ec5b4","colab":{"base_uri":"https://localhost:8080/"}},"source":["def subset(train_set, num_timestamps):\n","    if isinstance(train_set,list):\n","        new_train_set = []\n","        new_train_set.append(train_set[0][-num_timestamps:])\n","        new_train_set.append(train_set[1][-num_timestamps:])\n","    else:\n","        new_train_set = train_set[-num_timestamps:]\n","    return new_train_set\n","\n","dic_rmse = {}\n","for i in range(0,1):\n","    \n","    print(\"compiling model...\")\n","\n","    # lr_callback = LearningRateScheduler(lrschedule)\n","\n","    model = build_model(external_dim, save_model_pic=False)\n","\n","    hyperparams_name = 'TaxiNYC.c{}.p{}.t{}.resunit{}.iter{}'.format(\n","        len_closeness, len_period, len_trend, nb_residual_unit, i)\n","    fname_param = os.path.join(path_model, '{}.best.h5'.format(hyperparams_name))\n","    print(hyperparams_name)\n","\n","    early_stopping = EarlyStopping(monitor='val_rmse', patience=24, mode='min')\n","    model_checkpoint = ModelCheckpoint(\n","        fname_param, monitor='val_rmse', verbose=1, save_best_only=True, mode='min')\n","\n","    print('=' * 10)\n","    print(\"training model...\")\n","    history = model.fit(#subset(X_train, 4000), subset(Y_train, 4000),\n","                        X_train, Y_train,\n","                        epochs=nb_epoch,\n","                        batch_size=batch_size,\n","                        validation_data=(X_val,Y_val),\n","                        callbacks=[early_stopping, model_checkpoint],\n","                        verbose=1)\n","    model.save_weights(os.path.join(\n","        path_model, '{}.h5'.format(hyperparams_name)), overwrite=True)\n","    pickle.dump((history.history), open(os.path.join(\n","        path_result, '{}.history.pkl'.format(hyperparams_name)), 'wb'))\n","\n","    print('=' * 10)\n","    print('evaluating using the model that has the best loss on the valid set')\n","\n","    model.load_weights(fname_param)\n","    \n","    score = model.evaluate(\n","        X_test, Y_test, batch_size=Y_test.shape[0], verbose=0)\n","    print('Test score: %.6f rmse (norm): %.6f rmse (real): %.6f' %\n","          (score[0], score[1], score[1] * (mmn._max - mmn._min) / 2. ))"],"execution_count":9,"outputs":[{"output_type":"stream","text":["compiling model...\n","TaxiNYC.c3.p1.t1.resunit2.iter0\n","==========\n","training model...\n","Epoch 1/100\n","2469/2469 [==============================] - ETA: 0s - loss: 0.0113 - rmse: 0.0423\n","Epoch 00001: val_rmse improved from inf to 0.01208, saving model to MODEL/TaxiNYC.c3.p1.t1.resunit2.iter0.best.h5\n","2469/2469 [==============================] - 11s 4ms/step - loss: 0.0113 - rmse: 0.0423 - val_loss: 1.4898e-04 - val_rmse: 0.0121\n","Epoch 2/100\n","2463/2469 [============================>.] - ETA: 0s - loss: 1.2281e-04 - rmse: 0.0108\n","Epoch 00002: val_rmse improved from 0.01208 to 0.00958, saving model to MODEL/TaxiNYC.c3.p1.t1.resunit2.iter0.best.h5\n","2469/2469 [==============================] - 10s 4ms/step - loss: 1.2269e-04 - rmse: 0.0107 - val_loss: 9.3961e-05 - val_rmse: 0.0096\n","Epoch 3/100\n","2467/2469 [============================>.] - ETA: 0s - loss: 8.7664e-05 - rmse: 0.0090\n","Epoch 00003: val_rmse improved from 0.00958 to 0.00839, saving model to MODEL/TaxiNYC.c3.p1.t1.resunit2.iter0.best.h5\n","2469/2469 [==============================] - 10s 4ms/step - loss: 8.7653e-05 - rmse: 0.0090 - val_loss: 7.1867e-05 - val_rmse: 0.0084\n","Epoch 4/100\n","2459/2469 [============================>.] - ETA: 0s - loss: 7.5125e-05 - rmse: 0.0082\n","Epoch 00004: val_rmse did not improve from 0.00839\n","2469/2469 [==============================] - 10s 4ms/step - loss: 7.5036e-05 - rmse: 0.0082 - val_loss: 1.2277e-04 - val_rmse: 0.0110\n","Epoch 5/100\n","2461/2469 [============================>.] - ETA: 0s - loss: 6.5759e-05 - rmse: 0.0077\n","Epoch 00005: val_rmse did not improve from 0.00839\n","2469/2469 [==============================] - 10s 4ms/step - loss: 6.5767e-05 - rmse: 0.0077 - val_loss: 8.0738e-05 - val_rmse: 0.0089\n","Epoch 6/100\n","2458/2469 [============================>.] - ETA: 0s - loss: 5.9194e-05 - rmse: 0.0073\n","Epoch 00006: val_rmse improved from 0.00839 to 0.00774, saving model to MODEL/TaxiNYC.c3.p1.t1.resunit2.iter0.best.h5\n","2469/2469 [==============================] - 10s 4ms/step - loss: 5.9105e-05 - rmse: 0.0073 - val_loss: 6.1482e-05 - val_rmse: 0.0077\n","Epoch 7/100\n","2465/2469 [============================>.] - ETA: 0s - loss: 5.4751e-05 - rmse: 0.0070\n","Epoch 00007: val_rmse did not improve from 0.00774\n","2469/2469 [==============================] - 11s 4ms/step - loss: 5.4804e-05 - rmse: 0.0070 - val_loss: 0.0051 - val_rmse: 0.0707\n","Epoch 8/100\n","2464/2469 [============================>.] - ETA: 0s - loss: 5.1052e-05 - rmse: 0.0067\n","Epoch 00008: val_rmse did not improve from 0.00774\n","2469/2469 [==============================] - 10s 4ms/step - loss: 5.1041e-05 - rmse: 0.0067 - val_loss: 1.9116e-04 - val_rmse: 0.0138\n","Epoch 9/100\n","2458/2469 [============================>.] - ETA: 0s - loss: 4.8923e-05 - rmse: 0.0065\n","Epoch 00009: val_rmse improved from 0.00774 to 0.00713, saving model to MODEL/TaxiNYC.c3.p1.t1.resunit2.iter0.best.h5\n","2469/2469 [==============================] - 10s 4ms/step - loss: 4.8888e-05 - rmse: 0.0065 - val_loss: 5.1438e-05 - val_rmse: 0.0071\n","Epoch 10/100\n","2464/2469 [============================>.] - ETA: 0s - loss: 4.5836e-05 - rmse: 0.0063\n","Epoch 00010: val_rmse improved from 0.00713 to 0.00697, saving model to MODEL/TaxiNYC.c3.p1.t1.resunit2.iter0.best.h5\n","2469/2469 [==============================] - 10s 4ms/step - loss: 4.5801e-05 - rmse: 0.0063 - val_loss: 4.9678e-05 - val_rmse: 0.0070\n","Epoch 11/100\n","2461/2469 [============================>.] - ETA: 0s - loss: 4.5024e-05 - rmse: 0.0063\n","Epoch 00011: val_rmse improved from 0.00697 to 0.00675, saving model to MODEL/TaxiNYC.c3.p1.t1.resunit2.iter0.best.h5\n","2469/2469 [==============================] - 10s 4ms/step - loss: 4.4975e-05 - rmse: 0.0063 - val_loss: 4.6723e-05 - val_rmse: 0.0068\n","Epoch 12/100\n","2459/2469 [============================>.] - ETA: 0s - loss: 4.3128e-05 - rmse: 0.0061\n","Epoch 00012: val_rmse did not improve from 0.00675\n","2469/2469 [==============================] - 10s 4ms/step - loss: 4.3093e-05 - rmse: 0.0061 - val_loss: 1.2041e-04 - val_rmse: 0.0109\n","Epoch 13/100\n","2464/2469 [============================>.] - ETA: 0s - loss: 4.2019e-05 - rmse: 0.0060\n","Epoch 00013: val_rmse did not improve from 0.00675\n","2469/2469 [==============================] - 10s 4ms/step - loss: 4.2011e-05 - rmse: 0.0060 - val_loss: 8.2525e-05 - val_rmse: 0.0091\n","Epoch 14/100\n","2459/2469 [============================>.] - ETA: 0s - loss: 4.0989e-05 - rmse: 0.0059\n","Epoch 00014: val_rmse did not improve from 0.00675\n","2469/2469 [==============================] - 10s 4ms/step - loss: 4.1075e-05 - rmse: 0.0059 - val_loss: 5.2124e-04 - val_rmse: 0.0227\n","Epoch 15/100\n","2465/2469 [============================>.] - ETA: 0s - loss: 3.9640e-05 - rmse: 0.0058\n","Epoch 00015: val_rmse did not improve from 0.00675\n","2469/2469 [==============================] - 10s 4ms/step - loss: 3.9612e-05 - rmse: 0.0058 - val_loss: 7.6026e-05 - val_rmse: 0.0087\n","Epoch 16/100\n","2457/2469 [============================>.] - ETA: 0s - loss: 3.8721e-05 - rmse: 0.0058\n","Epoch 00016: val_rmse did not improve from 0.00675\n","2469/2469 [==============================] - 10s 4ms/step - loss: 3.8691e-05 - rmse: 0.0058 - val_loss: 6.1141e-05 - val_rmse: 0.0078\n","Epoch 17/100\n","2467/2469 [============================>.] - ETA: 0s - loss: 3.8491e-05 - rmse: 0.0057\n","Epoch 00017: val_rmse did not improve from 0.00675\n","2469/2469 [==============================] - 10s 4ms/step - loss: 3.8487e-05 - rmse: 0.0057 - val_loss: 7.4744e-05 - val_rmse: 0.0086\n","Epoch 18/100\n","2459/2469 [============================>.] - ETA: 0s - loss: 3.7272e-05 - rmse: 0.0057\n","Epoch 00018: val_rmse did not improve from 0.00675\n","2469/2469 [==============================] - 10s 4ms/step - loss: 3.7373e-05 - rmse: 0.0057 - val_loss: 5.2416e-05 - val_rmse: 0.0072\n","Epoch 19/100\n","2465/2469 [============================>.] - ETA: 0s - loss: 3.8164e-05 - rmse: 0.0057\n","Epoch 00019: val_rmse did not improve from 0.00675\n","2469/2469 [==============================] - 10s 4ms/step - loss: 3.8142e-05 - rmse: 0.0057 - val_loss: 7.5880e-05 - val_rmse: 0.0087\n","Epoch 20/100\n","2464/2469 [============================>.] - ETA: 0s - loss: 3.6172e-05 - rmse: 0.0056\n","Epoch 00020: val_rmse improved from 0.00675 to 0.00648, saving model to MODEL/TaxiNYC.c3.p1.t1.resunit2.iter0.best.h5\n","2469/2469 [==============================] - 10s 4ms/step - loss: 3.6152e-05 - rmse: 0.0056 - val_loss: 4.2670e-05 - val_rmse: 0.0065\n","Epoch 21/100\n","2462/2469 [============================>.] - ETA: 0s - loss: 3.5493e-05 - rmse: 0.0055\n","Epoch 00021: val_rmse did not improve from 0.00648\n","2469/2469 [==============================] - 10s 4ms/step - loss: 3.5507e-05 - rmse: 0.0055 - val_loss: 4.4197e-05 - val_rmse: 0.0066\n","Epoch 22/100\n","2458/2469 [============================>.] - ETA: 0s - loss: 3.5126e-05 - rmse: 0.0055\n","Epoch 00022: val_rmse improved from 0.00648 to 0.00614, saving model to MODEL/TaxiNYC.c3.p1.t1.resunit2.iter0.best.h5\n","2469/2469 [==============================] - 10s 4ms/step - loss: 3.5085e-05 - rmse: 0.0055 - val_loss: 3.8481e-05 - val_rmse: 0.0061\n","Epoch 23/100\n","2461/2469 [============================>.] - ETA: 0s - loss: 3.5075e-05 - rmse: 0.0055\n","Epoch 00023: val_rmse did not improve from 0.00614\n","2469/2469 [==============================] - 10s 4ms/step - loss: 3.5045e-05 - rmse: 0.0055 - val_loss: 1.6594e-04 - val_rmse: 0.0128\n","Epoch 24/100\n","2459/2469 [============================>.] - ETA: 0s - loss: 3.4395e-05 - rmse: 0.0054\n","Epoch 00024: val_rmse did not improve from 0.00614\n","2469/2469 [==============================] - 10s 4ms/step - loss: 3.4377e-05 - rmse: 0.0054 - val_loss: 9.4640e-05 - val_rmse: 0.0097\n","Epoch 25/100\n","2466/2469 [============================>.] - ETA: 0s - loss: 3.3835e-05 - rmse: 0.0054\n","Epoch 00025: val_rmse did not improve from 0.00614\n","2469/2469 [==============================] - 10s 4ms/step - loss: 3.4144e-05 - rmse: 0.0054 - val_loss: 5.8465e-05 - val_rmse: 0.0076\n","Epoch 26/100\n","2456/2469 [============================>.] - ETA: 0s - loss: 3.4369e-05 - rmse: 0.0054\n","Epoch 00026: val_rmse improved from 0.00614 to 0.00601, saving model to MODEL/TaxiNYC.c3.p1.t1.resunit2.iter0.best.h5\n","2469/2469 [==============================] - 10s 4ms/step - loss: 3.4344e-05 - rmse: 0.0054 - val_loss: 3.6751e-05 - val_rmse: 0.0060\n","Epoch 27/100\n","2464/2469 [============================>.] - ETA: 0s - loss: 3.3065e-05 - rmse: 0.0053\n","Epoch 00027: val_rmse improved from 0.00601 to 0.00541, saving model to MODEL/TaxiNYC.c3.p1.t1.resunit2.iter0.best.h5\n","2469/2469 [==============================] - 10s 4ms/step - loss: 3.3055e-05 - rmse: 0.0053 - val_loss: 2.9739e-05 - val_rmse: 0.0054\n","Epoch 28/100\n","2463/2469 [============================>.] - ETA: 0s - loss: 3.3316e-05 - rmse: 0.0053\n","Epoch 00028: val_rmse did not improve from 0.00541\n","2469/2469 [==============================] - 10s 4ms/step - loss: 3.3311e-05 - rmse: 0.0053 - val_loss: 8.9046e-05 - val_rmse: 0.0094\n","Epoch 29/100\n","2465/2469 [============================>.] - ETA: 0s - loss: 3.3225e-05 - rmse: 0.0053\n","Epoch 00029: val_rmse did not improve from 0.00541\n","2469/2469 [==============================] - 10s 4ms/step - loss: 3.3215e-05 - rmse: 0.0053 - val_loss: 8.3645e-05 - val_rmse: 0.0091\n","Epoch 30/100\n","2458/2469 [============================>.] - ETA: 0s - loss: 3.2765e-05 - rmse: 0.0052\n","Epoch 00030: val_rmse did not improve from 0.00541\n","2469/2469 [==============================] - 10s 4ms/step - loss: 3.2772e-05 - rmse: 0.0053 - val_loss: 4.0573e-05 - val_rmse: 0.0063\n","Epoch 31/100\n","2462/2469 [============================>.] - ETA: 0s - loss: 3.2235e-05 - rmse: 0.0052\n","Epoch 00031: val_rmse did not improve from 0.00541\n","2469/2469 [==============================] - 10s 4ms/step - loss: 3.2220e-05 - rmse: 0.0052 - val_loss: 8.9025e-05 - val_rmse: 0.0093\n","Epoch 32/100\n","2468/2469 [============================>.] - ETA: 0s - loss: 3.1602e-05 - rmse: 0.0052\n","Epoch 00032: val_rmse did not improve from 0.00541\n","2469/2469 [==============================] - 10s 4ms/step - loss: 3.1600e-05 - rmse: 0.0052 - val_loss: 9.1900e-05 - val_rmse: 0.0095\n","Epoch 33/100\n","2468/2469 [============================>.] - ETA: 0s - loss: 3.1456e-05 - rmse: 0.0052\n","Epoch 00033: val_rmse did not improve from 0.00541\n","2469/2469 [==============================] - 10s 4ms/step - loss: 3.1460e-05 - rmse: 0.0052 - val_loss: 4.7363e-05 - val_rmse: 0.0068\n","Epoch 34/100\n","2460/2469 [============================>.] - ETA: 0s - loss: 3.1492e-05 - rmse: 0.0052\n","Epoch 00034: val_rmse did not improve from 0.00541\n","2469/2469 [==============================] - 10s 4ms/step - loss: 3.1475e-05 - rmse: 0.0052 - val_loss: 4.4182e-05 - val_rmse: 0.0066\n","Epoch 35/100\n","2467/2469 [============================>.] - ETA: 0s - loss: 3.0930e-05 - rmse: 0.0051\n","Epoch 00035: val_rmse improved from 0.00541 to 0.00526, saving model to MODEL/TaxiNYC.c3.p1.t1.resunit2.iter0.best.h5\n","2469/2469 [==============================] - 10s 4ms/step - loss: 3.0925e-05 - rmse: 0.0051 - val_loss: 2.8179e-05 - val_rmse: 0.0053\n","Epoch 36/100\n","2463/2469 [============================>.] - ETA: 0s - loss: 3.0677e-05 - rmse: 0.0051\n","Epoch 00036: val_rmse did not improve from 0.00526\n","2469/2469 [==============================] - 10s 4ms/step - loss: 3.0644e-05 - rmse: 0.0051 - val_loss: 6.6673e-05 - val_rmse: 0.0081\n","Epoch 37/100\n","2460/2469 [============================>.] - ETA: 0s - loss: 3.0460e-05 - rmse: 0.0051\n","Epoch 00037: val_rmse did not improve from 0.00526\n","2469/2469 [==============================] - 10s 4ms/step - loss: 3.0436e-05 - rmse: 0.0051 - val_loss: 1.4175e-04 - val_rmse: 0.0118\n","Epoch 38/100\n","2463/2469 [============================>.] - ETA: 0s - loss: 2.9992e-05 - rmse: 0.0050\n","Epoch 00038: val_rmse did not improve from 0.00526\n","2469/2469 [==============================] - 10s 4ms/step - loss: 2.9972e-05 - rmse: 0.0050 - val_loss: 5.2698e-05 - val_rmse: 0.0072\n","Epoch 39/100\n","2465/2469 [============================>.] - ETA: 0s - loss: 3.0091e-05 - rmse: 0.0050\n","Epoch 00039: val_rmse did not improve from 0.00526\n","2469/2469 [==============================] - 10s 4ms/step - loss: 3.0078e-05 - rmse: 0.0050 - val_loss: 3.1365e-05 - val_rmse: 0.0056\n","Epoch 40/100\n","2465/2469 [============================>.] - ETA: 0s - loss: 2.9606e-05 - rmse: 0.0050\n","Epoch 00040: val_rmse did not improve from 0.00526\n","2469/2469 [==============================] - 10s 4ms/step - loss: 2.9653e-05 - rmse: 0.0050 - val_loss: 1.5663e-04 - val_rmse: 0.0125\n","Epoch 41/100\n","2466/2469 [============================>.] - ETA: 0s - loss: 2.9417e-05 - rmse: 0.0050\n","Epoch 00041: val_rmse did not improve from 0.00526\n","2469/2469 [==============================] - 10s 4ms/step - loss: 2.9414e-05 - rmse: 0.0050 - val_loss: 1.6064e-04 - val_rmse: 0.0126\n","Epoch 42/100\n","2457/2469 [============================>.] - ETA: 0s - loss: 2.9296e-05 - rmse: 0.0050\n","Epoch 00042: val_rmse did not improve from 0.00526\n","2469/2469 [==============================] - 10s 4ms/step - loss: 2.9275e-05 - rmse: 0.0050 - val_loss: 7.8843e-05 - val_rmse: 0.0088\n","Epoch 43/100\n","2459/2469 [============================>.] - ETA: 0s - loss: 2.9204e-05 - rmse: 0.0050\n","Epoch 00043: val_rmse did not improve from 0.00526\n","2469/2469 [==============================] - 10s 4ms/step - loss: 2.9189e-05 - rmse: 0.0050 - val_loss: 4.2718e-05 - val_rmse: 0.0065\n","Epoch 44/100\n","2457/2469 [============================>.] - ETA: 0s - loss: 2.8915e-05 - rmse: 0.0049\n","Epoch 00044: val_rmse did not improve from 0.00526\n","2469/2469 [==============================] - 10s 4ms/step - loss: 2.8890e-05 - rmse: 0.0049 - val_loss: 6.4270e-05 - val_rmse: 0.0080\n","Epoch 45/100\n","2456/2469 [============================>.] - ETA: 0s - loss: 2.8693e-05 - rmse: 0.0049\n","Epoch 00045: val_rmse did not improve from 0.00526\n","2469/2469 [==============================] - 10s 4ms/step - loss: 2.8712e-05 - rmse: 0.0049 - val_loss: 9.9833e-05 - val_rmse: 0.0099\n","Epoch 46/100\n","2469/2469 [==============================] - ETA: 0s - loss: 2.8621e-05 - rmse: 0.0049\n","Epoch 00046: val_rmse did not improve from 0.00526\n","2469/2469 [==============================] - 10s 4ms/step - loss: 2.8621e-05 - rmse: 0.0049 - val_loss: 7.0082e-05 - val_rmse: 0.0083\n","Epoch 47/100\n","2458/2469 [============================>.] - ETA: 0s - loss: 2.8579e-05 - rmse: 0.0049\n","Epoch 00047: val_rmse did not improve from 0.00526\n","2469/2469 [==============================] - 10s 4ms/step - loss: 2.8553e-05 - rmse: 0.0049 - val_loss: 1.0004e-04 - val_rmse: 0.0100\n","Epoch 48/100\n","2464/2469 [============================>.] - ETA: 0s - loss: 2.8195e-05 - rmse: 0.0049\n","Epoch 00048: val_rmse did not improve from 0.00526\n","2469/2469 [==============================] - 10s 4ms/step - loss: 2.8179e-05 - rmse: 0.0049 - val_loss: 1.6516e-04 - val_rmse: 0.0128\n","Epoch 49/100\n","2461/2469 [============================>.] - ETA: 0s - loss: 2.8032e-05 - rmse: 0.0049\n","Epoch 00049: val_rmse did not improve from 0.00526\n","2469/2469 [==============================] - 10s 4ms/step - loss: 2.8026e-05 - rmse: 0.0049 - val_loss: 6.9976e-05 - val_rmse: 0.0083\n","Epoch 50/100\n","2461/2469 [============================>.] - ETA: 0s - loss: 2.7775e-05 - rmse: 0.0048\n","Epoch 00050: val_rmse did not improve from 0.00526\n","2469/2469 [==============================] - 10s 4ms/step - loss: 2.7792e-05 - rmse: 0.0048 - val_loss: 3.7168e-05 - val_rmse: 0.0060\n","Epoch 51/100\n","2462/2469 [============================>.] - ETA: 0s - loss: 2.7421e-05 - rmse: 0.0048\n","Epoch 00051: val_rmse did not improve from 0.00526\n","2469/2469 [==============================] - 10s 4ms/step - loss: 2.7799e-05 - rmse: 0.0048 - val_loss: 9.3362e-05 - val_rmse: 0.0096\n","Epoch 52/100\n","2466/2469 [============================>.] - ETA: 0s - loss: 2.7733e-05 - rmse: 0.0048\n","Epoch 00052: val_rmse did not improve from 0.00526\n","2469/2469 [==============================] - 10s 4ms/step - loss: 2.7742e-05 - rmse: 0.0048 - val_loss: 1.0291e-04 - val_rmse: 0.0101\n","Epoch 53/100\n","2457/2469 [============================>.] - ETA: 0s - loss: 2.7805e-05 - rmse: 0.0048\n","Epoch 00053: val_rmse did not improve from 0.00526\n","2469/2469 [==============================] - 10s 4ms/step - loss: 2.7807e-05 - rmse: 0.0048 - val_loss: 3.3715e-05 - val_rmse: 0.0058\n","Epoch 54/100\n","2458/2469 [============================>.] - ETA: 0s - loss: 2.7238e-05 - rmse: 0.0048\n","Epoch 00054: val_rmse did not improve from 0.00526\n","2469/2469 [==============================] - 10s 4ms/step - loss: 2.7210e-05 - rmse: 0.0048 - val_loss: 8.9338e-05 - val_rmse: 0.0094\n","Epoch 55/100\n","2458/2469 [============================>.] - ETA: 0s - loss: 2.7153e-05 - rmse: 0.0048\n","Epoch 00055: val_rmse did not improve from 0.00526\n","2469/2469 [==============================] - 10s 4ms/step - loss: 2.7126e-05 - rmse: 0.0048 - val_loss: 4.9625e-05 - val_rmse: 0.0070\n","Epoch 56/100\n","2461/2469 [============================>.] - ETA: 0s - loss: 2.6881e-05 - rmse: 0.0048\n","Epoch 00056: val_rmse did not improve from 0.00526\n","2469/2469 [==============================] - 10s 4ms/step - loss: 2.6868e-05 - rmse: 0.0048 - val_loss: 5.9873e-05 - val_rmse: 0.0077\n","Epoch 57/100\n","2462/2469 [============================>.] - ETA: 0s - loss: 2.6621e-05 - rmse: 0.0047\n","Epoch 00057: val_rmse did not improve from 0.00526\n","2469/2469 [==============================] - 10s 4ms/step - loss: 2.6808e-05 - rmse: 0.0047 - val_loss: 1.2578e-04 - val_rmse: 0.0111\n","Epoch 58/100\n","2466/2469 [============================>.] - ETA: 0s - loss: 2.6697e-05 - rmse: 0.0048\n","Epoch 00058: val_rmse did not improve from 0.00526\n","2469/2469 [==============================] - 10s 4ms/step - loss: 2.6689e-05 - rmse: 0.0047 - val_loss: 7.2520e-05 - val_rmse: 0.0085\n","Epoch 59/100\n","2459/2469 [============================>.] - ETA: 0s - loss: 2.6692e-05 - rmse: 0.0047\n","Epoch 00059: val_rmse did not improve from 0.00526\n","2469/2469 [==============================] - 10s 4ms/step - loss: 2.6684e-05 - rmse: 0.0047 - val_loss: 3.9591e-05 - val_rmse: 0.0062\n","==========\n","evaluating using the model that has the best loss on the valid set\n","Test score: 0.000031 rmse (norm): 0.005603 rmse (real): 38.820017\n"],"name":"stdout"}]}]}