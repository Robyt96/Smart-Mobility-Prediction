{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"STAR_TaxiBJ.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"iRoEAmsdgRJ6","executionInfo":{"status":"ok","timestamp":1605109038938,"user_tz":-60,"elapsed":40100,"user":{"displayName":"Roberto Tagliabue","photoUrl":"","userId":"09447467556359440393"}},"outputId":"80925501-94c3-4e0a-b50b-63c88aa60b3d","colab":{"base_uri":"https://localhost:8080/"}},"source":["from google.colab import drive\n","drive.mount('/content/drive/', force_remount=True)\n","import os\n","os.chdir('./drive/My Drive/TESI/STAR')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive/\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"K1R1W7aEwemW"},"source":["# content = {\n","#     \"epsilon\": 1e-07, \n","#     \"floatx\": \"float32\", \n","#     \"image_data_format\": \"channels_first\", \n","#     \"backend\": \"tensorflow\"\n","# }\n","# with open(\"/root/.keras/keras.json\" , \"w\") as f:\n","#   f.write(str(content))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"vJO-wTDuYNMO"},"source":["# !cat /root/.keras/keras.json"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"FLsUC3dEWm_s"},"source":["import keras, tensorflow\n","print(keras.__version__)\n","print(tensorflow.__version__)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"x8TforZ4gSQh","executionInfo":{"status":"ok","timestamp":1605109091477,"user_tz":-60,"elapsed":7238,"user":{"displayName":"Roberto Tagliabue","photoUrl":"","userId":"09447467556359440393"}}},"source":["from __future__ import print_function\n","import sys\n","import pickle as pickle\n","import time\n","import h5py\n","\n","import star.metrics as metrics\n","from keras.optimizers import Adam\n","from keras.callbacks import EarlyStopping, ModelCheckpoint, TensorBoard, CSVLogger\n","from star.model import *\n","from star import TaxiBJ\n","from star.multi_step import *\n","np.random.seed(1337)  # for reproducibility"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"W3lQAE_uiInx","executionInfo":{"status":"ok","timestamp":1605109098960,"user_tz":-60,"elapsed":989,"user":{"displayName":"Roberto Tagliabue","photoUrl":"","userId":"09447467556359440393"}}},"source":["DATAPATH = '../data'  \n","CACHEDATA = True  # cache data or NOT\n","nb_epoch = 100 # number of epoch at training stage\n","# nb_epoch_cont =  100 # number of epoch at training (cont) stage\n","batch_size = 16  # batch size\n","T = 48  # number of time intervals in one day\n","lr = 0.00015 # learning rate\n","\n","len_closeness = 3 # length of closeness dependent sequence\n","len_period = 1 # length of peroid dependent sequence\n","len_trend = 1 # length of trend dependent sequence\n","nb_residual_unit = 6\n","nb_flow = 2  # there are two types of flows: inflow and outflow\n","# divide data into two subsets: Train & Test, of which the test set is the\n","# last 4 weeks\n","days_test = 7*4\n","len_test = T*days_test\n","len_val = 2*len_test\n","map_height, map_width = 32, 32  # grid size\n","\n","path_log = 'log_BJ'\n","muilt_step = False\n","\n","path_cache = os.path.join(DATAPATH, 'CACHE', 'STAR')  # cache path\n","path_result = 'RET'\n","path_model = 'MODEL'\n","if os.path.isdir(path_result) is False:\n","    os.mkdir(path_result)\n","if os.path.isdir(path_model) is False:\n","    os.mkdir(path_model)\n","if CACHEDATA and os.path.isdir(path_cache) is False:\n","    os.mkdir(path_cache)"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"xNlFnNJ8jisH","executionInfo":{"status":"ok","timestamp":1605109102969,"user_tz":-60,"elapsed":1000,"user":{"displayName":"Roberto Tagliabue","photoUrl":"","userId":"09447467556359440393"}}},"source":["def build_model(external_dim, save_model_pic=False):\n","    c_conf = (len_closeness, nb_flow, map_height,\n","              map_width) if len_closeness > 0 else None\n","    p_conf = (len_period, nb_flow, map_height,\n","              map_width) if len_period > 0 else None\n","    t_conf = (len_trend, nb_flow, map_height,\n","              map_width) if len_trend > 0 else None\n","    model = STAR(c_conf=c_conf, p_conf=p_conf, t_conf=t_conf,\n","                     external_dim=external_dim, nb_residual_unit=nb_residual_unit)\n","    # sgd = SGD(lr=lr, momentum=0.9, decay=5e-4, nesterov=True)\n","    adam = Adam(lr=lr)\n","    model.compile(loss='mse', optimizer=adam, metrics=[metrics.rmse])\n","    # model.summary()\n","    if (save_model_pic):\n","        from keras.utils.vis_utils import plot_model\n","        plot_model(model, to_file='TaxiBJ_model.png', show_shapes=True)\n","\n","    return model"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"pexv7nOAjjRi","executionInfo":{"status":"ok","timestamp":1605109105864,"user_tz":-60,"elapsed":1013,"user":{"displayName":"Roberto Tagliabue","photoUrl":"","userId":"09447467556359440393"}}},"source":["def read_cache(fname):\n","    mmn = pickle.load(open('preprocessing_bj.pkl', 'rb'))\n","\n","    f = h5py.File(fname, 'r')\n","    num = int(f['num'].value)\n","    X_train_all, Y_train_all, X_train, Y_train, X_val, Y_val, X_test, Y_test = [], [], [], [], [], [], [], []\n","    for i in range(num):\n","        X_train_all.append(f['X_train_all_%i' % i].value)\n","        X_train.append(f['X_train_%i' % i].value)\n","        X_val.append(f['X_val_%i' % i].value)\n","        X_test.append(f['X_test_%i' % i].value)\n","    Y_train_all = f['Y_train_all'].value\n","    Y_train = f['Y_train'].value\n","    Y_val = f['Y_val'].value\n","    Y_test = f['Y_test'].value\n","    external_dim = f['external_dim'].value\n","    timestamp_train_all = f['T_train_all'].value\n","    timestamp_train = f['T_train'].value\n","    timestamp_val = f['T_val'].value\n","    timestamp_test = f['T_test'].value\n","    f.close()\n","\n","    return X_train_all, Y_train_all, X_train, Y_train, X_val, Y_val, X_test, Y_test, mmn, external_dim, timestamp_train_all, timestamp_train, timestamp_val, timestamp_test"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"yac7jGnZjoED","executionInfo":{"status":"ok","timestamp":1605109108329,"user_tz":-60,"elapsed":983,"user":{"displayName":"Roberto Tagliabue","photoUrl":"","userId":"09447467556359440393"}}},"source":["def cache(fname, X_train_all, Y_train_all, X_train, Y_train, X_val, Y_val, X_test, Y_test, external_dim, timestamp_train_all, timestamp_train, timestamp_val, timestamp_test):\n","    h5 = h5py.File(fname, 'w')\n","    h5.create_dataset('num', data=len(X_train_all))\n","\n","    for i, data in enumerate(X_train_all):\n","        h5.create_dataset('X_train_all_%i' % i, data=data)\n","    for i, data in enumerate(X_train):\n","        h5.create_dataset('X_train_%i' % i, data=data)\n","    for i, data in enumerate(X_val):\n","        h5.create_dataset('X_val_%i' % i, data=data)\n","    # for i, data in enumerate(Y_train):\n","    for i, data in enumerate(X_test):\n","        h5.create_dataset('X_test_%i' % i, data=data)\n","\n","    h5.create_dataset('Y_train_all', data=Y_train_all)\n","    h5.create_dataset('Y_train', data=Y_train)\n","    h5.create_dataset('Y_val', data=Y_val)\n","    h5.create_dataset('Y_test', data=Y_test)\n","    external_dim = -1 if external_dim is None else int(external_dim)\n","    h5.create_dataset('external_dim', data=external_dim)\n","    h5.create_dataset('T_train_all', data=timestamp_train_all)\n","    h5.create_dataset('T_train', data=timestamp_train)\n","    h5.create_dataset('T_val', data=timestamp_val)\n","    h5.create_dataset('T_test', data=timestamp_test)\n","    h5.close()"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"ATaZm2o_gScy","executionInfo":{"status":"ok","timestamp":1605109195419,"user_tz":-60,"elapsed":84470,"user":{"displayName":"Roberto Tagliabue","photoUrl":"","userId":"09447467556359440393"}},"outputId":"79b13391-714f-4afa-80b0-e59722029b9f","colab":{"base_uri":"https://localhost:8080/"}},"source":["if muilt_step:\n","    dic_rmse={}\n","    list_muilt_rmse=[]\n","print(\"loading data...\")\n","ts = time.time()\n","fname = os.path.join(path_cache, 'TaxiBJ_C{}_P{}_T{}.h5'.format(\n","    len_closeness, len_period, len_trend))\n","if os.path.exists(fname) and CACHEDATA:\n","    X_train_all, Y_train_all, X_train, Y_train, \\\n","    X_val, Y_val, X_test, Y_test, mmn, external_dim, \\\n","    timestamp_train_all, timestamp_train, timestamp_val, timestamp_test = read_cache(\n","        fname)\n","    print(\"load %s successfully\" % fname)\n","else:\n","    X_train_all, Y_train_all, X_train, Y_train, \\\n","    X_val, Y_val, X_test, Y_test, mmn, external_dim, \\\n","    timestamp_train_all, timestamp_train, timestamp_val, timestamp_test = TaxiBJ.load_data(\n","        T=T, nb_flow=nb_flow, len_closeness=len_closeness, len_period=len_period, len_trend=len_trend, len_test=len_test,\n","        len_val=len_val, preprocess_name='preprocessing_bj.pkl', meta_data=True, meteorol_data=True, holiday_data=True, datapath=DATAPATH)\n","    if CACHEDATA:\n","        cache(fname, X_train_all, Y_train_all, X_train, Y_train, X_val, Y_val, X_test, Y_test,\n","              external_dim, timestamp_train_all, timestamp_train, timestamp_val, timestamp_test)\n","i = 0\n","print(external_dim)\n","print(\"\\n days (test): \", [v[:8] for v in timestamp_test[0::T]])\n","print(\"\\nelapsed time (loading data): %.3f seconds\\n\" % (time.time() - ts))\n","\n","print('=' * 10)"],"execution_count":7,"outputs":[{"output_type":"stream","text":["loading data...\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:5: H5pyDeprecationWarning: dataset.value has been deprecated. Use dataset[()] instead.\n","  \"\"\"\n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:8: H5pyDeprecationWarning: dataset.value has been deprecated. Use dataset[()] instead.\n","  \n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:9: H5pyDeprecationWarning: dataset.value has been deprecated. Use dataset[()] instead.\n","  if __name__ == '__main__':\n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:10: H5pyDeprecationWarning: dataset.value has been deprecated. Use dataset[()] instead.\n","  # Remove the CWD from sys.path while we load stuff.\n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:11: H5pyDeprecationWarning: dataset.value has been deprecated. Use dataset[()] instead.\n","  # This is added back by InteractiveShellApp.init_path()\n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:12: H5pyDeprecationWarning: dataset.value has been deprecated. Use dataset[()] instead.\n","  if sys.path[0] == '':\n"],"name":"stderr"},{"output_type":"stream","text":["load ../data/CACHE/STAR/TaxiBJ_C3_P1_T1.h5 successfully\n","28\n","\n"," days (test):  [b'20160309', b'20160310', b'20160311', b'20160312', b'20160313', b'20160314', b'20160315', b'20160316', b'20160317', b'20160318', b'20160319', b'20160320', b'20160321', b'20160322', b'20160325', b'20160326', b'20160327', b'20160328', b'20160329', b'20160401', b'20160402', b'20160403', b'20160404', b'20160405', b'20160406', b'20160407', b'20160408', b'20160409']\n","\n","elapsed time (loading data): 83.558 seconds\n","\n","==========\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:13: H5pyDeprecationWarning: dataset.value has been deprecated. Use dataset[()] instead.\n","  del sys.path[0]\n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:14: H5pyDeprecationWarning: dataset.value has been deprecated. Use dataset[()] instead.\n","  \n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:15: H5pyDeprecationWarning: dataset.value has been deprecated. Use dataset[()] instead.\n","  from ipykernel import kernelapp as app\n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:16: H5pyDeprecationWarning: dataset.value has been deprecated. Use dataset[()] instead.\n","  app.launch_new_instance()\n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:17: H5pyDeprecationWarning: dataset.value has been deprecated. Use dataset[()] instead.\n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:18: H5pyDeprecationWarning: dataset.value has been deprecated. Use dataset[()] instead.\n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:19: H5pyDeprecationWarning: dataset.value has been deprecated. Use dataset[()] instead.\n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:20: H5pyDeprecationWarning: dataset.value has been deprecated. Use dataset[()] instead.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"yY1zm-Tt-ahB","executionInfo":{"status":"ok","timestamp":1605109216256,"user_tz":-60,"elapsed":953,"user":{"displayName":"Roberto Tagliabue","photoUrl":"","userId":"09447467556359440393"}},"outputId":"d505736d-8430-4e3e-b240-17f651ac7791","colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["tf.keras.backend.set_image_data_format('channels_first')\n","tf.keras.backend.image_data_format()"],"execution_count":8,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'channels_first'"]},"metadata":{"tags":[]},"execution_count":8}]},{"cell_type":"code","metadata":{"id":"xXwkbPL24XH8","executionInfo":{"status":"ok","timestamp":1605109370538,"user_tz":-60,"elapsed":1121,"user":{"displayName":"Roberto Tagliabue","photoUrl":"","userId":"09447467556359440393"}},"outputId":"0dd32e86-8133-48c0-fd37-e0b46ae43671","colab":{"base_uri":"https://localhost:8080/"}},"source":["print(\"compiling model...\")\n","\n","ts = time.time()\n","print('external dim:', external_dim)\n","\n","model = build_model(external_dim, save_model_pic=False)\n","\n","hyperparams_name = 'TaxiBJ.c{}.p{}.t{}.resunit{}.lr{}.iter{}'.format(\n","    len_closeness, len_period, len_trend, nb_residual_unit, lr, i)\n","fname_param = os.path.join(path_model, '{}.best.h5'.format(hyperparams_name))\n","\n","csv = CSVLogger(os.path.join(path_result, hyperparams_name+'.csv'), separator=',', append=False)\n","early_stopping = EarlyStopping(monitor='val_rmse', patience=24, mode='min')#4\n","model_checkpoint = ModelCheckpoint(\n","    fname_param, monitor='val_rmse', verbose=2, save_best_only=True, mode='min')\n","\n","print(\"\\nelapsed time (compiling model): %.3f seconds\\n\" %\n","      (time.time() - ts))"],"execution_count":11,"outputs":[{"output_type":"stream","text":["compiling model...\n","external dim: 28\n","\n","elapsed time (compiling model): 0.223 seconds\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"6MUMsc8g75LF","executionInfo":{"status":"ok","timestamp":1602336712705,"user_tz":-120,"elapsed":722,"user":{"displayName":"Roberto Tagliabue","photoUrl":"","userId":"09447467556359440393"}},"outputId":"d02a9910-e451-4de8-8cb2-bf070fe9de11","colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["model.summary()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Model: \"functional_5\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_6 (InputLayer)            [(None, 28)]         0                                            \n","__________________________________________________________________________________________________\n","dense_4 (Dense)                 (None, 10)           290         input_6[0][0]                    \n","__________________________________________________________________________________________________\n","dense_5 (Dense)                 (None, 2048)         22528       dense_4[0][0]                    \n","__________________________________________________________________________________________________\n","input_5 (InputLayer)            [(None, 14, 32, 32)] 0                                            \n","__________________________________________________________________________________________________\n","reshape_2 (Reshape)             (None, 2, 32, 32)    0           dense_5[0][0]                    \n","__________________________________________________________________________________________________\n","concatenate_2 (Concatenate)     (None, 16, 32, 32)   0           input_5[0][0]                    \n","                                                                 reshape_2[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_12 (Conv2D)              (None, 64, 32, 32)   9280        concatenate_2[0][0]              \n","__________________________________________________________________________________________________\n","activation_12 (Activation)      (None, 64, 32, 32)   0           conv2d_12[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_13 (Conv2D)              (None, 64, 32, 32)   36928       activation_12[0][0]              \n","__________________________________________________________________________________________________\n","activation_13 (Activation)      (None, 64, 32, 32)   0           conv2d_13[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_14 (Conv2D)              (None, 64, 32, 32)   36928       activation_13[0][0]              \n","__________________________________________________________________________________________________\n","add_4 (Add)                     (None, 64, 32, 32)   0           conv2d_12[0][0]                  \n","                                                                 conv2d_14[0][0]                  \n","__________________________________________________________________________________________________\n","activation_14 (Activation)      (None, 64, 32, 32)   0           add_4[0][0]                      \n","__________________________________________________________________________________________________\n","conv2d_15 (Conv2D)              (None, 64, 32, 32)   36928       activation_14[0][0]              \n","__________________________________________________________________________________________________\n","activation_15 (Activation)      (None, 64, 32, 32)   0           conv2d_15[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_16 (Conv2D)              (None, 64, 32, 32)   36928       activation_15[0][0]              \n","__________________________________________________________________________________________________\n","add_5 (Add)                     (None, 64, 32, 32)   0           add_4[0][0]                      \n","                                                                 conv2d_16[0][0]                  \n","__________________________________________________________________________________________________\n","activation_16 (Activation)      (None, 64, 32, 32)   0           add_5[0][0]                      \n","__________________________________________________________________________________________________\n","conv2d_17 (Conv2D)              (None, 64, 32, 32)   36928       activation_16[0][0]              \n","__________________________________________________________________________________________________\n","activation_17 (Activation)      (None, 64, 32, 32)   0           conv2d_17[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_18 (Conv2D)              (None, 64, 32, 32)   36928       activation_17[0][0]              \n","__________________________________________________________________________________________________\n","add_6 (Add)                     (None, 64, 32, 32)   0           add_5[0][0]                      \n","                                                                 conv2d_18[0][0]                  \n","__________________________________________________________________________________________________\n","activation_18 (Activation)      (None, 64, 32, 32)   0           add_6[0][0]                      \n","__________________________________________________________________________________________________\n","conv2d_19 (Conv2D)              (None, 64, 32, 32)   36928       activation_18[0][0]              \n","__________________________________________________________________________________________________\n","activation_19 (Activation)      (None, 64, 32, 32)   0           conv2d_19[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_20 (Conv2D)              (None, 64, 32, 32)   36928       activation_19[0][0]              \n","__________________________________________________________________________________________________\n","add_7 (Add)                     (None, 64, 32, 32)   0           add_6[0][0]                      \n","                                                                 conv2d_20[0][0]                  \n","__________________________________________________________________________________________________\n","activation_20 (Activation)      (None, 64, 32, 32)   0           add_7[0][0]                      \n","__________________________________________________________________________________________________\n","conv2d_21 (Conv2D)              (None, 64, 32, 32)   36928       activation_20[0][0]              \n","__________________________________________________________________________________________________\n","activation_21 (Activation)      (None, 64, 32, 32)   0           conv2d_21[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_22 (Conv2D)              (None, 64, 32, 32)   36928       activation_21[0][0]              \n","__________________________________________________________________________________________________\n","add_8 (Add)                     (None, 64, 32, 32)   0           add_7[0][0]                      \n","                                                                 conv2d_22[0][0]                  \n","__________________________________________________________________________________________________\n","activation_22 (Activation)      (None, 64, 32, 32)   0           add_8[0][0]                      \n","__________________________________________________________________________________________________\n","conv2d_23 (Conv2D)              (None, 64, 32, 32)   36928       activation_22[0][0]              \n","__________________________________________________________________________________________________\n","activation_23 (Activation)      (None, 64, 32, 32)   0           conv2d_23[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_24 (Conv2D)              (None, 64, 32, 32)   36928       activation_23[0][0]              \n","__________________________________________________________________________________________________\n","add_9 (Add)                     (None, 64, 32, 32)   0           add_8[0][0]                      \n","                                                                 conv2d_24[0][0]                  \n","__________________________________________________________________________________________________\n","activation_24 (Activation)      (None, 64, 32, 32)   0           add_9[0][0]                      \n","__________________________________________________________________________________________________\n","conv2d_25 (Conv2D)              (None, 2, 32, 32)    1154        activation_24[0][0]              \n","__________________________________________________________________________________________________\n","activation_25 (Activation)      (None, 2, 32, 32)    0           conv2d_25[0][0]                  \n","==================================================================================================\n","Total params: 476,388\n","Trainable params: 476,388\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"3QTfXJs37RLk","executionInfo":{"status":"ok","timestamp":1605113368506,"user_tz":-60,"elapsed":3993923,"user":{"displayName":"Roberto Tagliabue","photoUrl":"","userId":"09447467556359440393"}},"outputId":"ba63c13f-370a-49b7-c014-162729d0060a","colab":{"base_uri":"https://localhost:8080/"}},"source":["i = 0\n","history = model.fit(X_train, Y_train,\n","                    epochs=nb_epoch,\n","                    batch_size=batch_size,\n","                    #validation_split=0.15,\n","                    validation_data=(X_val,Y_val),\n","                    callbacks=[#TensorBoard(log_dir=os.path.join(path_log, '{}_step1_plot_{}'.format(hyperparams_name, i))),\n","                                early_stopping,\n","                                model_checkpoint],\n","                    verbose=1)\n","\n","model.save_weights(os.path.join(\n","    path_model, '{}.h5'.format(hyperparams_name)), overwrite=True)\n","\n","pickle.dump((history.history), open(os.path.join(\n","    path_result, '{}.history.pkl'.format(hyperparams_name)), 'wb'))\n","print(\"\\nelapsed time (training): %.3f seconds\\n\" % (time.time() - ts))\n","\n","print('=' * 10)"],"execution_count":12,"outputs":[{"output_type":"stream","text":["Epoch 1/100\n","770/770 [==============================] - ETA: 0s - loss: 0.0156 - rmse: 0.0830\n","Epoch 00001: val_rmse improved from inf to 0.03715, saving model to MODEL/TaxiBJ.c3.p1.t1.resunit6.lr0.00015.iter0.best.h5\n","770/770 [==============================] - 41s 54ms/step - loss: 0.0156 - rmse: 0.0830 - val_loss: 0.0015 - val_rmse: 0.0372\n","Epoch 2/100\n","769/770 [============================>.] - ETA: 0s - loss: 0.0013 - rmse: 0.0360\n","Epoch 00002: val_rmse improved from 0.03715 to 0.03293, saving model to MODEL/TaxiBJ.c3.p1.t1.resunit6.lr0.00015.iter0.best.h5\n","770/770 [==============================] - 40s 52ms/step - loss: 0.0013 - rmse: 0.0360 - val_loss: 0.0011 - val_rmse: 0.0329\n","Epoch 3/100\n","769/770 [============================>.] - ETA: 0s - loss: 0.0012 - rmse: 0.0337\n","Epoch 00003: val_rmse improved from 0.03293 to 0.03146, saving model to MODEL/TaxiBJ.c3.p1.t1.resunit6.lr0.00015.iter0.best.h5\n","770/770 [==============================] - 40s 52ms/step - loss: 0.0012 - rmse: 0.0337 - val_loss: 0.0010 - val_rmse: 0.0315\n","Epoch 4/100\n","769/770 [============================>.] - ETA: 0s - loss: 0.0011 - rmse: 0.0320\n","Epoch 00004: val_rmse improved from 0.03146 to 0.02927, saving model to MODEL/TaxiBJ.c3.p1.t1.resunit6.lr0.00015.iter0.best.h5\n","770/770 [==============================] - 40s 52ms/step - loss: 0.0011 - rmse: 0.0320 - val_loss: 9.2727e-04 - val_rmse: 0.0293\n","Epoch 5/100\n","769/770 [============================>.] - ETA: 0s - loss: 0.0010 - rmse: 0.0314\n","Epoch 00005: val_rmse did not improve from 0.02927\n","770/770 [==============================] - 39s 51ms/step - loss: 0.0010 - rmse: 0.0314 - val_loss: 9.9247e-04 - val_rmse: 0.0304\n","Epoch 6/100\n","769/770 [============================>.] - ETA: 0s - loss: 9.7694e-04 - rmse: 0.0307\n","Epoch 00006: val_rmse did not improve from 0.02927\n","770/770 [==============================] - 39s 51ms/step - loss: 9.7680e-04 - rmse: 0.0307 - val_loss: 9.8180e-04 - val_rmse: 0.0298\n","Epoch 7/100\n","769/770 [============================>.] - ETA: 0s - loss: 9.5642e-04 - rmse: 0.0303\n","Epoch 00007: val_rmse improved from 0.02927 to 0.02713, saving model to MODEL/TaxiBJ.c3.p1.t1.resunit6.lr0.00015.iter0.best.h5\n","770/770 [==============================] - 40s 52ms/step - loss: 9.5606e-04 - rmse: 0.0303 - val_loss: 7.9366e-04 - val_rmse: 0.0271\n","Epoch 8/100\n","769/770 [============================>.] - ETA: 0s - loss: 9.3824e-04 - rmse: 0.0301\n","Epoch 00008: val_rmse did not improve from 0.02713\n","770/770 [==============================] - 39s 51ms/step - loss: 9.3842e-04 - rmse: 0.0301 - val_loss: 0.0012 - val_rmse: 0.0325\n","Epoch 9/100\n","770/770 [==============================] - ETA: 0s - loss: 9.3239e-04 - rmse: 0.0300\n","Epoch 00009: val_rmse improved from 0.02713 to 0.02607, saving model to MODEL/TaxiBJ.c3.p1.t1.resunit6.lr0.00015.iter0.best.h5\n","770/770 [==============================] - 40s 52ms/step - loss: 9.3239e-04 - rmse: 0.0300 - val_loss: 7.4251e-04 - val_rmse: 0.0261\n","Epoch 10/100\n","769/770 [============================>.] - ETA: 0s - loss: 8.9232e-04 - rmse: 0.0293\n","Epoch 00010: val_rmse did not improve from 0.02607\n","770/770 [==============================] - 40s 51ms/step - loss: 8.9289e-04 - rmse: 0.0293 - val_loss: 0.0011 - val_rmse: 0.0323\n","Epoch 11/100\n","769/770 [============================>.] - ETA: 0s - loss: 8.9639e-04 - rmse: 0.0293\n","Epoch 00011: val_rmse did not improve from 0.02607\n","770/770 [==============================] - 39s 51ms/step - loss: 8.9632e-04 - rmse: 0.0293 - val_loss: 8.4405e-04 - val_rmse: 0.0276\n","Epoch 12/100\n","770/770 [==============================] - ETA: 0s - loss: 8.7102e-04 - rmse: 0.0289\n","Epoch 00012: val_rmse did not improve from 0.02607\n","770/770 [==============================] - 40s 51ms/step - loss: 8.7102e-04 - rmse: 0.0289 - val_loss: 8.5123e-04 - val_rmse: 0.0278\n","Epoch 13/100\n","769/770 [============================>.] - ETA: 0s - loss: 8.7247e-04 - rmse: 0.0289\n","Epoch 00013: val_rmse did not improve from 0.02607\n","770/770 [==============================] - 39s 51ms/step - loss: 8.7213e-04 - rmse: 0.0289 - val_loss: 7.7612e-04 - val_rmse: 0.0266\n","Epoch 14/100\n","770/770 [==============================] - ETA: 0s - loss: 8.4401e-04 - rmse: 0.0284\n","Epoch 00014: val_rmse improved from 0.02607 to 0.02518, saving model to MODEL/TaxiBJ.c3.p1.t1.resunit6.lr0.00015.iter0.best.h5\n","770/770 [==============================] - 40s 52ms/step - loss: 8.4401e-04 - rmse: 0.0284 - val_loss: 6.9466e-04 - val_rmse: 0.0252\n","Epoch 15/100\n","769/770 [============================>.] - ETA: 0s - loss: 8.5539e-04 - rmse: 0.0287\n","Epoch 00015: val_rmse did not improve from 0.02518\n","770/770 [==============================] - 39s 51ms/step - loss: 8.5531e-04 - rmse: 0.0287 - val_loss: 7.4873e-04 - val_rmse: 0.0264\n","Epoch 16/100\n","769/770 [============================>.] - ETA: 0s - loss: 8.3583e-04 - rmse: 0.0283\n","Epoch 00016: val_rmse did not improve from 0.02518\n","770/770 [==============================] - 40s 51ms/step - loss: 8.3600e-04 - rmse: 0.0283 - val_loss: 8.5914e-04 - val_rmse: 0.0278\n","Epoch 17/100\n","769/770 [============================>.] - ETA: 0s - loss: 8.3115e-04 - rmse: 0.0282\n","Epoch 00017: val_rmse did not improve from 0.02518\n","770/770 [==============================] - 39s 51ms/step - loss: 8.3154e-04 - rmse: 0.0282 - val_loss: 0.0012 - val_rmse: 0.0335\n","Epoch 18/100\n","769/770 [============================>.] - ETA: 0s - loss: 8.2463e-04 - rmse: 0.0281\n","Epoch 00018: val_rmse did not improve from 0.02518\n","770/770 [==============================] - 40s 52ms/step - loss: 8.2496e-04 - rmse: 0.0281 - val_loss: 8.2508e-04 - val_rmse: 0.0278\n","Epoch 19/100\n","769/770 [============================>.] - ETA: 0s - loss: 8.1620e-04 - rmse: 0.0280\n","Epoch 00019: val_rmse did not improve from 0.02518\n","770/770 [==============================] - 39s 51ms/step - loss: 8.1607e-04 - rmse: 0.0280 - val_loss: 7.4640e-04 - val_rmse: 0.0261\n","Epoch 20/100\n","769/770 [============================>.] - ETA: 0s - loss: 8.1538e-04 - rmse: 0.0279\n","Epoch 00020: val_rmse improved from 0.02518 to 0.02497, saving model to MODEL/TaxiBJ.c3.p1.t1.resunit6.lr0.00015.iter0.best.h5\n","770/770 [==============================] - 40s 52ms/step - loss: 8.1510e-04 - rmse: 0.0279 - val_loss: 6.7571e-04 - val_rmse: 0.0250\n","Epoch 21/100\n","770/770 [==============================] - ETA: 0s - loss: 8.0092e-04 - rmse: 0.0277\n","Epoch 00021: val_rmse did not improve from 0.02497\n","770/770 [==============================] - 40s 51ms/step - loss: 8.0092e-04 - rmse: 0.0277 - val_loss: 8.0373e-04 - val_rmse: 0.0269\n","Epoch 22/100\n","769/770 [============================>.] - ETA: 0s - loss: 7.8575e-04 - rmse: 0.0274\n","Epoch 00022: val_rmse did not improve from 0.02497\n","770/770 [==============================] - 40s 51ms/step - loss: 7.8572e-04 - rmse: 0.0274 - val_loss: 7.9912e-04 - val_rmse: 0.0271\n","Epoch 23/100\n","769/770 [============================>.] - ETA: 0s - loss: 7.8978e-04 - rmse: 0.0275\n","Epoch 00023: val_rmse did not improve from 0.02497\n","770/770 [==============================] - 40s 52ms/step - loss: 7.8960e-04 - rmse: 0.0275 - val_loss: 6.8029e-04 - val_rmse: 0.0251\n","Epoch 24/100\n","769/770 [============================>.] - ETA: 0s - loss: 7.8520e-04 - rmse: 0.0274\n","Epoch 00024: val_rmse did not improve from 0.02497\n","770/770 [==============================] - 40s 52ms/step - loss: 7.8525e-04 - rmse: 0.0274 - val_loss: 8.2707e-04 - val_rmse: 0.0278\n","Epoch 25/100\n","769/770 [============================>.] - ETA: 0s - loss: 7.8083e-04 - rmse: 0.0273\n","Epoch 00025: val_rmse did not improve from 0.02497\n","770/770 [==============================] - 40s 52ms/step - loss: 7.8135e-04 - rmse: 0.0274 - val_loss: 7.4580e-04 - val_rmse: 0.0262\n","Epoch 26/100\n","769/770 [============================>.] - ETA: 0s - loss: 7.7971e-04 - rmse: 0.0273\n","Epoch 00026: val_rmse did not improve from 0.02497\n","770/770 [==============================] - 40s 52ms/step - loss: 7.7970e-04 - rmse: 0.0273 - val_loss: 7.9787e-04 - val_rmse: 0.0274\n","Epoch 27/100\n","769/770 [============================>.] - ETA: 0s - loss: 7.8395e-04 - rmse: 0.0274\n","Epoch 00027: val_rmse did not improve from 0.02497\n","770/770 [==============================] - 39s 51ms/step - loss: 7.8377e-04 - rmse: 0.0274 - val_loss: 6.9140e-04 - val_rmse: 0.0251\n","Epoch 28/100\n","769/770 [============================>.] - ETA: 0s - loss: 7.5733e-04 - rmse: 0.0270\n","Epoch 00028: val_rmse did not improve from 0.02497\n","770/770 [==============================] - 40s 51ms/step - loss: 7.5735e-04 - rmse: 0.0270 - val_loss: 7.6718e-04 - val_rmse: 0.0266\n","Epoch 29/100\n","769/770 [============================>.] - ETA: 0s - loss: 7.6262e-04 - rmse: 0.0270\n","Epoch 00029: val_rmse improved from 0.02497 to 0.02496, saving model to MODEL/TaxiBJ.c3.p1.t1.resunit6.lr0.00015.iter0.best.h5\n","770/770 [==============================] - 40s 52ms/step - loss: 7.6252e-04 - rmse: 0.0270 - val_loss: 6.8409e-04 - val_rmse: 0.0250\n","Epoch 30/100\n","769/770 [============================>.] - ETA: 0s - loss: 7.5847e-04 - rmse: 0.0270\n","Epoch 00030: val_rmse improved from 0.02496 to 0.02481, saving model to MODEL/TaxiBJ.c3.p1.t1.resunit6.lr0.00015.iter0.best.h5\n","770/770 [==============================] - 40s 52ms/step - loss: 7.5836e-04 - rmse: 0.0270 - val_loss: 6.6375e-04 - val_rmse: 0.0248\n","Epoch 31/100\n","769/770 [============================>.] - ETA: 0s - loss: 7.5081e-04 - rmse: 0.0268\n","Epoch 00031: val_rmse improved from 0.02481 to 0.02419, saving model to MODEL/TaxiBJ.c3.p1.t1.resunit6.lr0.00015.iter0.best.h5\n","770/770 [==============================] - 40s 53ms/step - loss: 7.5066e-04 - rmse: 0.0268 - val_loss: 6.4348e-04 - val_rmse: 0.0242\n","Epoch 32/100\n","769/770 [============================>.] - ETA: 0s - loss: 7.5129e-04 - rmse: 0.0268\n","Epoch 00032: val_rmse did not improve from 0.02419\n","770/770 [==============================] - 40s 52ms/step - loss: 7.5108e-04 - rmse: 0.0268 - val_loss: 6.4525e-04 - val_rmse: 0.0243\n","Epoch 33/100\n","769/770 [============================>.] - ETA: 0s - loss: 7.4490e-04 - rmse: 0.0267\n","Epoch 00033: val_rmse did not improve from 0.02419\n","770/770 [==============================] - 40s 51ms/step - loss: 7.4453e-04 - rmse: 0.0267 - val_loss: 6.7971e-04 - val_rmse: 0.0251\n","Epoch 34/100\n","769/770 [============================>.] - ETA: 0s - loss: 7.4607e-04 - rmse: 0.0267\n","Epoch 00034: val_rmse did not improve from 0.02419\n","770/770 [==============================] - 40s 52ms/step - loss: 7.4577e-04 - rmse: 0.0267 - val_loss: 6.4194e-04 - val_rmse: 0.0244\n","Epoch 35/100\n","770/770 [==============================] - ETA: 0s - loss: 7.4581e-04 - rmse: 0.0267\n","Epoch 00035: val_rmse did not improve from 0.02419\n","770/770 [==============================] - 40s 51ms/step - loss: 7.4581e-04 - rmse: 0.0267 - val_loss: 7.1046e-04 - val_rmse: 0.0256\n","Epoch 36/100\n","770/770 [==============================] - ETA: 0s - loss: 7.2981e-04 - rmse: 0.0264\n","Epoch 00036: val_rmse improved from 0.02419 to 0.02410, saving model to MODEL/TaxiBJ.c3.p1.t1.resunit6.lr0.00015.iter0.best.h5\n","770/770 [==============================] - 40s 52ms/step - loss: 7.2981e-04 - rmse: 0.0264 - val_loss: 6.2992e-04 - val_rmse: 0.0241\n","Epoch 37/100\n","769/770 [============================>.] - ETA: 0s - loss: 7.3214e-04 - rmse: 0.0265\n","Epoch 00037: val_rmse did not improve from 0.02410\n","770/770 [==============================] - 40s 51ms/step - loss: 7.3190e-04 - rmse: 0.0265 - val_loss: 6.3983e-04 - val_rmse: 0.0242\n","Epoch 38/100\n","769/770 [============================>.] - ETA: 0s - loss: 7.2687e-04 - rmse: 0.0264\n","Epoch 00038: val_rmse improved from 0.02410 to 0.02397, saving model to MODEL/TaxiBJ.c3.p1.t1.resunit6.lr0.00015.iter0.best.h5\n","770/770 [==============================] - 40s 52ms/step - loss: 7.2678e-04 - rmse: 0.0264 - val_loss: 6.2606e-04 - val_rmse: 0.0240\n","Epoch 39/100\n","769/770 [============================>.] - ETA: 0s - loss: 7.3345e-04 - rmse: 0.0265\n","Epoch 00039: val_rmse improved from 0.02397 to 0.02367, saving model to MODEL/TaxiBJ.c3.p1.t1.resunit6.lr0.00015.iter0.best.h5\n","770/770 [==============================] - 40s 52ms/step - loss: 7.3353e-04 - rmse: 0.0265 - val_loss: 6.1671e-04 - val_rmse: 0.0237\n","Epoch 40/100\n","769/770 [============================>.] - ETA: 0s - loss: 7.2450e-04 - rmse: 0.0263\n","Epoch 00040: val_rmse did not improve from 0.02367\n","770/770 [==============================] - 40s 51ms/step - loss: 7.2471e-04 - rmse: 0.0263 - val_loss: 7.4941e-04 - val_rmse: 0.0263\n","Epoch 41/100\n","769/770 [============================>.] - ETA: 0s - loss: 7.2207e-04 - rmse: 0.0263\n","Epoch 00041: val_rmse did not improve from 0.02367\n","770/770 [==============================] - 40s 52ms/step - loss: 7.2222e-04 - rmse: 0.0263 - val_loss: 6.2341e-04 - val_rmse: 0.0240\n","Epoch 42/100\n","769/770 [============================>.] - ETA: 0s - loss: 7.1754e-04 - rmse: 0.0262\n","Epoch 00042: val_rmse did not improve from 0.02367\n","770/770 [==============================] - 40s 51ms/step - loss: 7.1752e-04 - rmse: 0.0262 - val_loss: 6.5643e-04 - val_rmse: 0.0246\n","Epoch 43/100\n","769/770 [============================>.] - ETA: 0s - loss: 7.1954e-04 - rmse: 0.0262\n","Epoch 00043: val_rmse did not improve from 0.02367\n","770/770 [==============================] - 40s 52ms/step - loss: 7.1956e-04 - rmse: 0.0262 - val_loss: 6.9387e-04 - val_rmse: 0.0253\n","Epoch 44/100\n","769/770 [============================>.] - ETA: 0s - loss: 7.1060e-04 - rmse: 0.0261\n","Epoch 00044: val_rmse did not improve from 0.02367\n","770/770 [==============================] - 40s 52ms/step - loss: 7.1150e-04 - rmse: 0.0261 - val_loss: 8.6807e-04 - val_rmse: 0.0279\n","Epoch 45/100\n","769/770 [============================>.] - ETA: 0s - loss: 7.1280e-04 - rmse: 0.0261\n","Epoch 00045: val_rmse did not improve from 0.02367\n","770/770 [==============================] - 40s 52ms/step - loss: 7.1295e-04 - rmse: 0.0261 - val_loss: 6.7067e-04 - val_rmse: 0.0247\n","Epoch 46/100\n","769/770 [============================>.] - ETA: 0s - loss: 7.0927e-04 - rmse: 0.0261\n","Epoch 00046: val_rmse did not improve from 0.02367\n","770/770 [==============================] - 40s 52ms/step - loss: 7.0937e-04 - rmse: 0.0261 - val_loss: 6.5831e-04 - val_rmse: 0.0245\n","Epoch 47/100\n","769/770 [============================>.] - ETA: 0s - loss: 7.0923e-04 - rmse: 0.0261\n","Epoch 00047: val_rmse did not improve from 0.02367\n","770/770 [==============================] - 40s 52ms/step - loss: 7.0924e-04 - rmse: 0.0261 - val_loss: 6.0844e-04 - val_rmse: 0.0237\n","Epoch 48/100\n","769/770 [============================>.] - ETA: 0s - loss: 7.0200e-04 - rmse: 0.0259\n","Epoch 00048: val_rmse did not improve from 0.02367\n","770/770 [==============================] - 40s 52ms/step - loss: 7.0180e-04 - rmse: 0.0259 - val_loss: 6.2026e-04 - val_rmse: 0.0239\n","Epoch 49/100\n","770/770 [==============================] - ETA: 0s - loss: 6.9137e-04 - rmse: 0.0257\n","Epoch 00049: val_rmse did not improve from 0.02367\n","770/770 [==============================] - 40s 52ms/step - loss: 6.9137e-04 - rmse: 0.0257 - val_loss: 7.1529e-04 - val_rmse: 0.0259\n","Epoch 50/100\n","769/770 [============================>.] - ETA: 0s - loss: 7.0187e-04 - rmse: 0.0259\n","Epoch 00050: val_rmse did not improve from 0.02367\n","770/770 [==============================] - 40s 51ms/step - loss: 7.0173e-04 - rmse: 0.0259 - val_loss: 6.2162e-04 - val_rmse: 0.0239\n","Epoch 51/100\n","769/770 [============================>.] - ETA: 0s - loss: 7.0289e-04 - rmse: 0.0260\n","Epoch 00051: val_rmse improved from 0.02367 to 0.02316, saving model to MODEL/TaxiBJ.c3.p1.t1.resunit6.lr0.00015.iter0.best.h5\n","770/770 [==============================] - 40s 52ms/step - loss: 7.0281e-04 - rmse: 0.0260 - val_loss: 5.8911e-04 - val_rmse: 0.0232\n","Epoch 52/100\n","769/770 [============================>.] - ETA: 0s - loss: 6.9797e-04 - rmse: 0.0259\n","Epoch 00052: val_rmse did not improve from 0.02316\n","770/770 [==============================] - 40s 52ms/step - loss: 6.9772e-04 - rmse: 0.0259 - val_loss: 6.1473e-04 - val_rmse: 0.0238\n","Epoch 53/100\n","769/770 [============================>.] - ETA: 0s - loss: 7.0400e-04 - rmse: 0.0260\n","Epoch 00053: val_rmse did not improve from 0.02316\n","770/770 [==============================] - 40s 52ms/step - loss: 7.0391e-04 - rmse: 0.0260 - val_loss: 6.0244e-04 - val_rmse: 0.0234\n","Epoch 54/100\n","769/770 [============================>.] - ETA: 0s - loss: 6.9136e-04 - rmse: 0.0257\n","Epoch 00054: val_rmse did not improve from 0.02316\n","770/770 [==============================] - 40s 52ms/step - loss: 6.9128e-04 - rmse: 0.0257 - val_loss: 5.9363e-04 - val_rmse: 0.0233\n","Epoch 55/100\n","769/770 [============================>.] - ETA: 0s - loss: 6.9864e-04 - rmse: 0.0259\n","Epoch 00055: val_rmse did not improve from 0.02316\n","770/770 [==============================] - 40s 52ms/step - loss: 6.9860e-04 - rmse: 0.0259 - val_loss: 6.9114e-04 - val_rmse: 0.0254\n","Epoch 56/100\n","769/770 [============================>.] - ETA: 0s - loss: 6.9087e-04 - rmse: 0.0257\n","Epoch 00056: val_rmse did not improve from 0.02316\n","770/770 [==============================] - 40s 52ms/step - loss: 6.9077e-04 - rmse: 0.0257 - val_loss: 6.7326e-04 - val_rmse: 0.0251\n","Epoch 57/100\n","769/770 [============================>.] - ETA: 0s - loss: 6.8313e-04 - rmse: 0.0256\n","Epoch 00057: val_rmse did not improve from 0.02316\n","770/770 [==============================] - 40s 52ms/step - loss: 6.8289e-04 - rmse: 0.0256 - val_loss: 5.8137e-04 - val_rmse: 0.0232\n","Epoch 58/100\n","769/770 [============================>.] - ETA: 0s - loss: 6.7852e-04 - rmse: 0.0255\n","Epoch 00058: val_rmse did not improve from 0.02316\n","770/770 [==============================] - 40s 51ms/step - loss: 6.7827e-04 - rmse: 0.0255 - val_loss: 6.3368e-04 - val_rmse: 0.0242\n","Epoch 59/100\n","770/770 [==============================] - ETA: 0s - loss: 6.8803e-04 - rmse: 0.0257\n","Epoch 00059: val_rmse did not improve from 0.02316\n","770/770 [==============================] - 40s 52ms/step - loss: 6.8803e-04 - rmse: 0.0257 - val_loss: 6.4242e-04 - val_rmse: 0.0244\n","Epoch 60/100\n","769/770 [============================>.] - ETA: 0s - loss: 6.7829e-04 - rmse: 0.0255\n","Epoch 00060: val_rmse did not improve from 0.02316\n","770/770 [==============================] - 40s 52ms/step - loss: 6.7827e-04 - rmse: 0.0255 - val_loss: 7.4800e-04 - val_rmse: 0.0266\n","Epoch 61/100\n","769/770 [============================>.] - ETA: 0s - loss: 6.7737e-04 - rmse: 0.0255\n","Epoch 00061: val_rmse did not improve from 0.02316\n","770/770 [==============================] - 40s 52ms/step - loss: 6.7747e-04 - rmse: 0.0255 - val_loss: 7.7150e-04 - val_rmse: 0.0269\n","Epoch 62/100\n","769/770 [============================>.] - ETA: 0s - loss: 6.8433e-04 - rmse: 0.0256\n","Epoch 00062: val_rmse did not improve from 0.02316\n","770/770 [==============================] - 40s 52ms/step - loss: 6.8411e-04 - rmse: 0.0256 - val_loss: 5.9176e-04 - val_rmse: 0.0232\n","Epoch 63/100\n","769/770 [============================>.] - ETA: 0s - loss: 6.7494e-04 - rmse: 0.0254\n","Epoch 00063: val_rmse did not improve from 0.02316\n","770/770 [==============================] - 40s 52ms/step - loss: 6.7487e-04 - rmse: 0.0254 - val_loss: 6.7990e-04 - val_rmse: 0.0252\n","Epoch 64/100\n","769/770 [============================>.] - ETA: 0s - loss: 6.6404e-04 - rmse: 0.0253\n","Epoch 00064: val_rmse did not improve from 0.02316\n","770/770 [==============================] - 40s 52ms/step - loss: 6.6413e-04 - rmse: 0.0253 - val_loss: 5.9992e-04 - val_rmse: 0.0236\n","Epoch 65/100\n","769/770 [============================>.] - ETA: 0s - loss: 6.7351e-04 - rmse: 0.0254\n","Epoch 00065: val_rmse did not improve from 0.02316\n","770/770 [==============================] - 40s 52ms/step - loss: 6.7345e-04 - rmse: 0.0254 - val_loss: 6.0750e-04 - val_rmse: 0.0238\n","Epoch 66/100\n","769/770 [============================>.] - ETA: 0s - loss: 6.9020e-04 - rmse: 0.0258\n","Epoch 00066: val_rmse did not improve from 0.02316\n","770/770 [==============================] - 40s 52ms/step - loss: 6.9010e-04 - rmse: 0.0257 - val_loss: 6.1761e-04 - val_rmse: 0.0238\n","Epoch 67/100\n","769/770 [============================>.] - ETA: 0s - loss: 6.6645e-04 - rmse: 0.0253\n","Epoch 00067: val_rmse did not improve from 0.02316\n","770/770 [==============================] - 40s 52ms/step - loss: 6.6652e-04 - rmse: 0.0253 - val_loss: 5.7758e-04 - val_rmse: 0.0232\n","Epoch 68/100\n","769/770 [============================>.] - ETA: 0s - loss: 6.5626e-04 - rmse: 0.0251\n","Epoch 00068: val_rmse did not improve from 0.02316\n","770/770 [==============================] - 40s 52ms/step - loss: 6.5636e-04 - rmse: 0.0251 - val_loss: 8.5635e-04 - val_rmse: 0.0279\n","Epoch 69/100\n","770/770 [==============================] - ETA: 0s - loss: 6.7927e-04 - rmse: 0.0255\n","Epoch 00069: val_rmse improved from 0.02316 to 0.02302, saving model to MODEL/TaxiBJ.c3.p1.t1.resunit6.lr0.00015.iter0.best.h5\n","770/770 [==============================] - 41s 53ms/step - loss: 6.7927e-04 - rmse: 0.0255 - val_loss: 5.7425e-04 - val_rmse: 0.0230\n","Epoch 70/100\n","769/770 [============================>.] - ETA: 0s - loss: 6.6175e-04 - rmse: 0.0252\n","Epoch 00070: val_rmse did not improve from 0.02302\n","770/770 [==============================] - 40s 52ms/step - loss: 6.6292e-04 - rmse: 0.0252 - val_loss: 5.6832e-04 - val_rmse: 0.0230\n","Epoch 71/100\n","769/770 [============================>.] - ETA: 0s - loss: 6.5355e-04 - rmse: 0.0251\n","Epoch 00071: val_rmse improved from 0.02302 to 0.02296, saving model to MODEL/TaxiBJ.c3.p1.t1.resunit6.lr0.00015.iter0.best.h5\n","770/770 [==============================] - 41s 53ms/step - loss: 6.5350e-04 - rmse: 0.0251 - val_loss: 5.5436e-04 - val_rmse: 0.0230\n","Epoch 72/100\n","769/770 [============================>.] - ETA: 0s - loss: 6.5581e-04 - rmse: 0.0251\n","Epoch 00072: val_rmse did not improve from 0.02296\n","770/770 [==============================] - 40s 52ms/step - loss: 6.5572e-04 - rmse: 0.0251 - val_loss: 5.7699e-04 - val_rmse: 0.0233\n","Epoch 73/100\n","769/770 [============================>.] - ETA: 0s - loss: 6.5273e-04 - rmse: 0.0251\n","Epoch 00073: val_rmse did not improve from 0.02296\n","770/770 [==============================] - 40s 52ms/step - loss: 6.5295e-04 - rmse: 0.0251 - val_loss: 6.7096e-04 - val_rmse: 0.0249\n","Epoch 74/100\n","769/770 [============================>.] - ETA: 0s - loss: 6.5109e-04 - rmse: 0.0250\n","Epoch 00074: val_rmse did not improve from 0.02296\n","770/770 [==============================] - 40s 52ms/step - loss: 6.5098e-04 - rmse: 0.0250 - val_loss: 5.6669e-04 - val_rmse: 0.0232\n","Epoch 75/100\n","769/770 [============================>.] - ETA: 0s - loss: 6.4730e-04 - rmse: 0.0250\n","Epoch 00075: val_rmse did not improve from 0.02296\n","770/770 [==============================] - 40s 52ms/step - loss: 6.4729e-04 - rmse: 0.0250 - val_loss: 6.8751e-04 - val_rmse: 0.0257\n","Epoch 76/100\n","769/770 [============================>.] - ETA: 0s - loss: 6.6117e-04 - rmse: 0.0252\n","Epoch 00076: val_rmse did not improve from 0.02296\n","770/770 [==============================] - 40s 52ms/step - loss: 6.6108e-04 - rmse: 0.0252 - val_loss: 7.1874e-04 - val_rmse: 0.0255\n","Epoch 77/100\n","769/770 [============================>.] - ETA: 0s - loss: 6.4629e-04 - rmse: 0.0250\n","Epoch 00077: val_rmse did not improve from 0.02296\n","770/770 [==============================] - 40s 52ms/step - loss: 6.4625e-04 - rmse: 0.0250 - val_loss: 6.0095e-04 - val_rmse: 0.0238\n","Epoch 78/100\n","769/770 [============================>.] - ETA: 0s - loss: 6.4292e-04 - rmse: 0.0249\n","Epoch 00078: val_rmse did not improve from 0.02296\n","770/770 [==============================] - 40s 52ms/step - loss: 6.4276e-04 - rmse: 0.0249 - val_loss: 6.5321e-04 - val_rmse: 0.0244\n","Epoch 79/100\n","769/770 [============================>.] - ETA: 0s - loss: 6.4362e-04 - rmse: 0.0249\n","Epoch 00079: val_rmse did not improve from 0.02296\n","770/770 [==============================] - 40s 52ms/step - loss: 6.4337e-04 - rmse: 0.0249 - val_loss: 5.7036e-04 - val_rmse: 0.0231\n","Epoch 80/100\n","770/770 [==============================] - ETA: 0s - loss: 6.4013e-04 - rmse: 0.0248\n","Epoch 00080: val_rmse did not improve from 0.02296\n","770/770 [==============================] - 40s 52ms/step - loss: 6.4013e-04 - rmse: 0.0248 - val_loss: 7.3679e-04 - val_rmse: 0.0261\n","Epoch 81/100\n","769/770 [============================>.] - ETA: 0s - loss: 6.4259e-04 - rmse: 0.0249\n","Epoch 00081: val_rmse did not improve from 0.02296\n","770/770 [==============================] - 40s 52ms/step - loss: 6.4256e-04 - rmse: 0.0249 - val_loss: 5.7120e-04 - val_rmse: 0.0232\n","Epoch 82/100\n","769/770 [============================>.] - ETA: 0s - loss: 6.3591e-04 - rmse: 0.0248\n","Epoch 00082: val_rmse improved from 0.02296 to 0.02276, saving model to MODEL/TaxiBJ.c3.p1.t1.resunit6.lr0.00015.iter0.best.h5\n","770/770 [==============================] - 40s 53ms/step - loss: 6.3582e-04 - rmse: 0.0248 - val_loss: 5.4721e-04 - val_rmse: 0.0228\n","Epoch 83/100\n","769/770 [============================>.] - ETA: 0s - loss: 6.3005e-04 - rmse: 0.0247\n","Epoch 00083: val_rmse did not improve from 0.02276\n","770/770 [==============================] - 40s 52ms/step - loss: 6.2993e-04 - rmse: 0.0247 - val_loss: 7.0550e-04 - val_rmse: 0.0252\n","Epoch 84/100\n","769/770 [============================>.] - ETA: 0s - loss: 6.2606e-04 - rmse: 0.0246\n","Epoch 00084: val_rmse did not improve from 0.02276\n","770/770 [==============================] - 40s 52ms/step - loss: 6.2600e-04 - rmse: 0.0246 - val_loss: 8.0417e-04 - val_rmse: 0.0275\n","Epoch 85/100\n","769/770 [============================>.] - ETA: 0s - loss: 6.3412e-04 - rmse: 0.0247\n","Epoch 00085: val_rmse did not improve from 0.02276\n","770/770 [==============================] - 40s 52ms/step - loss: 6.3410e-04 - rmse: 0.0247 - val_loss: 5.6949e-04 - val_rmse: 0.0232\n","Epoch 86/100\n","769/770 [============================>.] - ETA: 0s - loss: 6.2115e-04 - rmse: 0.0245\n","Epoch 00086: val_rmse did not improve from 0.02276\n","770/770 [==============================] - 40s 52ms/step - loss: 6.2123e-04 - rmse: 0.0245 - val_loss: 6.4722e-04 - val_rmse: 0.0247\n","Epoch 87/100\n","769/770 [============================>.] - ETA: 0s - loss: 6.3414e-04 - rmse: 0.0247\n","Epoch 00087: val_rmse did not improve from 0.02276\n","770/770 [==============================] - 40s 52ms/step - loss: 6.3408e-04 - rmse: 0.0247 - val_loss: 6.1536e-04 - val_rmse: 0.0241\n","Epoch 88/100\n","769/770 [============================>.] - ETA: 0s - loss: 6.2915e-04 - rmse: 0.0247\n","Epoch 00088: val_rmse improved from 0.02276 to 0.02265, saving model to MODEL/TaxiBJ.c3.p1.t1.resunit6.lr0.00015.iter0.best.h5\n","770/770 [==============================] - 41s 53ms/step - loss: 6.2912e-04 - rmse: 0.0247 - val_loss: 5.4466e-04 - val_rmse: 0.0226\n","Epoch 89/100\n","769/770 [============================>.] - ETA: 0s - loss: 6.2538e-04 - rmse: 0.0246\n","Epoch 00089: val_rmse did not improve from 0.02265\n","770/770 [==============================] - 40s 52ms/step - loss: 6.2533e-04 - rmse: 0.0246 - val_loss: 7.3219e-04 - val_rmse: 0.0254\n","Epoch 90/100\n","769/770 [============================>.] - ETA: 0s - loss: 6.5371e-04 - rmse: 0.0251\n","Epoch 00090: val_rmse did not improve from 0.02265\n","770/770 [==============================] - 40s 52ms/step - loss: 6.5345e-04 - rmse: 0.0251 - val_loss: 5.9779e-04 - val_rmse: 0.0234\n","Epoch 91/100\n","769/770 [============================>.] - ETA: 0s - loss: 6.2167e-04 - rmse: 0.0245\n","Epoch 00091: val_rmse did not improve from 0.02265\n","770/770 [==============================] - 40s 52ms/step - loss: 6.2156e-04 - rmse: 0.0245 - val_loss: 5.8653e-04 - val_rmse: 0.0235\n","Epoch 92/100\n","769/770 [============================>.] - ETA: 0s - loss: 6.0849e-04 - rmse: 0.0243\n","Epoch 00092: val_rmse did not improve from 0.02265\n","770/770 [==============================] - 40s 52ms/step - loss: 6.0838e-04 - rmse: 0.0243 - val_loss: 6.2149e-04 - val_rmse: 0.0242\n","Epoch 93/100\n","769/770 [============================>.] - ETA: 0s - loss: 6.0612e-04 - rmse: 0.0242\n","Epoch 00093: val_rmse did not improve from 0.02265\n","770/770 [==============================] - 40s 52ms/step - loss: 6.0606e-04 - rmse: 0.0242 - val_loss: 5.9743e-04 - val_rmse: 0.0236\n","Epoch 94/100\n","769/770 [============================>.] - ETA: 0s - loss: 6.1718e-04 - rmse: 0.0244\n","Epoch 00094: val_rmse did not improve from 0.02265\n","770/770 [==============================] - 40s 52ms/step - loss: 6.1721e-04 - rmse: 0.0244 - val_loss: 5.7844e-04 - val_rmse: 0.0234\n","Epoch 95/100\n","770/770 [==============================] - ETA: 0s - loss: 6.1518e-04 - rmse: 0.0244\n","Epoch 00095: val_rmse did not improve from 0.02265\n","770/770 [==============================] - 40s 52ms/step - loss: 6.1518e-04 - rmse: 0.0244 - val_loss: 5.5970e-04 - val_rmse: 0.0230\n","Epoch 96/100\n","769/770 [============================>.] - ETA: 0s - loss: 6.2823e-04 - rmse: 0.0246\n","Epoch 00096: val_rmse did not improve from 0.02265\n","770/770 [==============================] - 40s 52ms/step - loss: 6.2826e-04 - rmse: 0.0246 - val_loss: 6.2798e-04 - val_rmse: 0.0241\n","Epoch 97/100\n","769/770 [============================>.] - ETA: 0s - loss: 5.9530e-04 - rmse: 0.0240\n","Epoch 00097: val_rmse did not improve from 0.02265\n","770/770 [==============================] - 39s 51ms/step - loss: 5.9524e-04 - rmse: 0.0240 - val_loss: 6.1470e-04 - val_rmse: 0.0241\n","Epoch 98/100\n","769/770 [============================>.] - ETA: 0s - loss: 5.9898e-04 - rmse: 0.0241\n","Epoch 00098: val_rmse did not improve from 0.02265\n","770/770 [==============================] - 39s 51ms/step - loss: 5.9890e-04 - rmse: 0.0241 - val_loss: 5.4994e-04 - val_rmse: 0.0228\n","Epoch 99/100\n","769/770 [============================>.] - ETA: 0s - loss: 6.1345e-04 - rmse: 0.0244\n","Epoch 00099: val_rmse improved from 0.02265 to 0.02251, saving model to MODEL/TaxiBJ.c3.p1.t1.resunit6.lr0.00015.iter0.best.h5\n","770/770 [==============================] - 40s 52ms/step - loss: 6.1332e-04 - rmse: 0.0244 - val_loss: 5.3603e-04 - val_rmse: 0.0225\n","Epoch 100/100\n","770/770 [==============================] - ETA: 0s - loss: 6.1857e-04 - rmse: 0.0244\n","Epoch 00100: val_rmse did not improve from 0.02251\n","770/770 [==============================] - 39s 51ms/step - loss: 6.1857e-04 - rmse: 0.0244 - val_loss: 6.5390e-04 - val_rmse: 0.0248\n","\n","elapsed time (training): 3998.128 seconds\n","\n","==========\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"mTS5BaZ7gSfr","executionInfo":{"status":"ok","timestamp":1605113466225,"user_tz":-60,"elapsed":8606,"user":{"displayName":"Roberto Tagliabue","photoUrl":"","userId":"09447467556359440393"}},"outputId":"c98160d8-b30f-4c4e-dd32-e39fa8a9cd25","colab":{"base_uri":"https://localhost:8080/"}},"source":["# evaluate\n","print('evaluating using the model that has the best loss on the valid set')\n","\n","model.load_weights(fname_param)\n","score = model.evaluate(\n","    X_test, Y_test, batch_size=Y_test.shape[0], verbose=0)\n","print('Test score: %.6f rmse (norm): %.6f rmse (real): %.6f' %\n","        (score[0], score[1], score[1] * (mmn._max - mmn._min) / 2.))"],"execution_count":13,"outputs":[{"output_type":"stream","text":["evaluating using the model that has the best loss on the valid set\n","Test score: 0.000621 rmse (norm): 0.024910 rmse (real): 16.091888\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"EjPsc-B8gSlM"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7Z6QNbXLgSoM"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZQ1E0JrugSrQ"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"CWHCwSN_gSuG"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"TVKRujrUgSwy"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"imYIBjVtgSzy"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7XrkSpEqgS2s"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2ghfnT90gS5e"},"source":[""],"execution_count":null,"outputs":[]}]}